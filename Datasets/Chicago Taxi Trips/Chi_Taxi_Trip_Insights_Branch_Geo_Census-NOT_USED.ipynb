{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806f2a20",
   "metadata": {},
   "source": [
    "```markdown\n",
    "# Overview of the Notebook\n",
    "\n",
    "This Jupyter Notebook is designed to process and analyze geographic data from the Chicago Taxi Trips dataset, leveraging Google BigQuery and other Python libraries. Below is a step-by-step explanation of the workflow:\n",
    "\n",
    "## 1. **Setup and Configuration**\n",
    "    - The notebook begins by importing necessary libraries such as `json`, `os`, `re`, `pandas`, and `pandas_gbq`.\n",
    "    - It loads configuration data from a JSON file (`locations_conf.json`) to retrieve directory paths and credentials for accessing Google Cloud services.\n",
    "\n",
    "## 2. **Google Cloud Authentication**\n",
    "    - The notebook uses the `google.oauth2.service_account` module to create credentials from a service account key file. These credentials are used to authenticate with Google Cloud services, including BigQuery.\n",
    "\n",
    "## 3. **Querying BigQuery**\n",
    "    - A SQL query is executed on the `bigquery-public-data.chicago_taxi_trips.taxi_trips` dataset to extract unique latitude and longitude values from both pickup and dropoff locations.\n",
    "    - The results are loaded into a Pandas DataFrame (`chi_geo_data`), and the number of rows and unique rows are calculated and displayed.\n",
    "\n",
    "## 4. **Reverse Geocoding**\n",
    "    - The notebook uses the `reverse_geocode` library to resolve human-readable location information (e.g., city, country) for each latitude and longitude pair in the dataset.\n",
    "    - The resolved data is stored in a new DataFrame (`geo_data_df`), and duplicate rows are removed to ensure uniqueness.\n",
    "\n",
    "## 5. **Loading Data to BigQuery**\n",
    "    - The processed geographic data is uploaded to a BigQuery table (`Chicago_Taxi_Trips.Geo_Locations`) using the `pandas_gbq.to_gbq` function. The table is replaced if it already exists.\n",
    "\n",
    "## 6. **Documentation**\n",
    "    - Markdown cells are used throughout the notebook to document each step of the workflow, making it easier to understand and maintain.\n",
    "\n",
    "## Key Variables\n",
    "    - `credentials`: Google Cloud credentials used for authentication.\n",
    "    - `locations_data`: A dictionary containing configuration data, including the path to the service account key file.\n",
    "    - `chi_geo_data`: A DataFrame containing unique latitude and longitude values from the Chicago Taxi dataset.\n",
    "    - `geo_data_df`: A DataFrame containing resolved location information for the geographic coordinates.\n",
    "\n",
    "## Purpose\n",
    "The primary goal of this notebook is to extract, process, and enrich geographic data from the Chicago Taxi Trips dataset and load the processed data into BigQuery for further analysis or visualization.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a8d31",
   "metadata": {},
   "source": [
    "## Get My BQ Credentials to Access the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da426c46",
   "metadata": {},
   "source": [
    "## Load Directory Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebbfcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common_Funcs_Dir: /Users/mike/Develop/Projects/Code Notebook/Common/Functions\n",
      "Credentials_Dir: /Users/mike/Develop/Projects/Code Notebook/Credentials\n",
      "Rel_Pickes_Dir: ../.pickles\n",
      "Pub_Data_Dir: '/Users/mike/Data/Public\n",
      "BQ_Service_Key: /Users/mike/Develop/Conf/GCP Service Keys/mikecancell-development-************.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Check if the file exists and load the JSON file into a dictionary\n",
    "file_path = r'C:\\Users\\mike\\Develop\\Projects\\Code Notebook\\Credentials\\locations_conf.json'\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    for key, value in locations_data.items():\n",
    "        if key == 'BQ_Service_Key' and isinstance(value, str):\n",
    "            # Mask the unique identifier part of the file name\n",
    "            masked_value = re.sub(r'([a-f0-9]{12})', '************', value)\n",
    "            print(f\"{key}: {masked_value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53902756",
   "metadata": {},
   "source": [
    "# Connect to Google Cloud\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4187c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "# Resolve the key path from the locations data\n",
    "key_path = locations_data.get('BQ_Service_Key', 'default_key_path.json')\n",
    "\n",
    "# Create credentials using the key file\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af296a",
   "metadata": {},
   "source": [
    "# Get all of the Unique Latitude and Longitude Values from the Chi Taxi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e95acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Total number of rows: 875\n",
      "Total number of unique rows: 875\n",
      "    latitude  longitude\n",
      "0  41.787279 -87.634342\n",
      "1  41.827613 -87.604242\n",
      "2  41.844145 -87.682996\n",
      "3  41.869119 -87.756068\n",
      "4  41.921701 -87.655912\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Total number of rows: 875\n",
      "Total number of unique rows: 875\n",
      "    latitude  longitude\n",
      "0  41.787279 -87.634342\n",
      "1  41.827613 -87.604242\n",
      "2  41.844145 -87.682996\n",
      "3  41.869119 -87.756068\n",
      "4  41.921701 -87.655912\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas_gbq.exceptions import LargeResultsWarning\n",
    "\n",
    "# Suppress the LargeResultsWarning\n",
    "warnings.simplefilter('ignore', category=LargeResultsWarning)\n",
    "\n",
    "# Import the pandas_gbq library\n",
    "import pandas_gbq\n",
    "\n",
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            latitude,\n",
    "            longitude\n",
    "        FROM (\n",
    "            SELECT \n",
    "            pickup_latitude AS latitude,\n",
    "            pickup_longitude AS longitude\n",
    "            FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "            UNION DISTINCT\n",
    "            SELECT \n",
    "            dropoff_latitude AS latitude,\n",
    "            dropoff_longitude AS longitude\n",
    "            FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "        )\n",
    "        WHERE latitude IS NOT NULL AND longitude IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Read the data from BigQuery into a pandas DataFrame\n",
    "chi_geo_data = pandas_gbq.read_gbq(query, project_id=credentials.project_id, credentials=credentials)\n",
    "\n",
    "# Print the total number of rows in the dataframe\n",
    "print(f\"Total number of rows: {len(chi_geo_data)}\")\n",
    "# Calculate and print the total number of unique rows\n",
    "num_unique_rows = len(chi_geo_data.drop_duplicates())\n",
    "print(f\"Total number of unique rows: {num_unique_rows}\")\n",
    "# Display the first few rows of the dataframe\n",
    "print(chi_geo_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f21b8",
   "metadata": {},
   "source": [
    "# Extract, process unique geo data from the Chi Taxi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe82c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country_code           city  latitude  longitude  population     state  \\\n",
      "0           US      Englewood  41.77976  -87.64588       26121  Illinois   \n",
      "1           US        Douglas  41.83476  -87.61811       20323  Illinois   \n",
      "2           US  McKinley Park  41.83170  -87.67366       15612  Illinois   \n",
      "3           US         Cicero  41.84559  -87.75394       83886  Illinois   \n",
      "4           US   Lincoln Park  41.92170  -87.64783       66959  Illinois   \n",
      "\n",
      "        county        country  \n",
      "0  Cook County  United States  \n",
      "1  Cook County  United States  \n",
      "2  Cook County  United States  \n",
      "3  Cook County  United States  \n",
      "4  Cook County  United States  \n",
      "Final number of rows in the new DataFrame: 875\n",
      "Number of duplicate rows: 811\n",
      "Final number of rows after removing duplicates: 64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import reverse_geocode\n",
    "# Use reverse_geocode to resolve location information for each latitude and longitude pair\n",
    "coordinates = chi_geo_data[['latitude', 'longitude']].to_records(index=False)\n",
    "coordinates = [(record.latitude, record.longitude) for record in coordinates]\n",
    "resolved_locations = reverse_geocode.search(coordinates)\n",
    "\n",
    "# Convert resolved locations into a new DataFrame\n",
    "geo_data_df = pd.DataFrame(resolved_locations)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(geo_data_df.head())\n",
    "\n",
    "# Print the final number of rows in the new DataFrame\n",
    "print(f\"Final number of rows in the new DataFrame: {len(geo_data_df)}\")\n",
    "num_duplicates = len(geo_data_df) - len(geo_data_df.drop_duplicates())\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "# Drop duplicate rows from the DataFrame\n",
    "geo_data_df = geo_data_df.drop_duplicates()\n",
    "\n",
    "# Print the final number of rows after removing duplicates\n",
    "print(f\"Final number of rows after removing duplicates: {len(geo_data_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9440c",
   "metadata": {},
   "source": [
    "# Load the Data to BiqQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ced1d812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16320.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded to Chicago_Taxi_Trips.Geo_Locations in BigQuery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the destination table in BigQuery\n",
    "destination_table = 'Chicago_Taxi_Trips.Geo_Locations'\n",
    "\n",
    "# Load the DataFrame to BigQuery\n",
    "pandas_gbq.to_gbq(geo_data_df, destination_table, project_id=credentials.project_id, credentials=credentials, if_exists='replace')\n",
    "\n",
    "print(f\"Data successfully loaded to {destination_table} in BigQuery.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
