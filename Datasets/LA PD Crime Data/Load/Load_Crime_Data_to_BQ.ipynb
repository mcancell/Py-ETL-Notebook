{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Conf and Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Directory Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Common_Funcs_Dir': '/Users/mike/Develop/Projects/Code Notebook/Common/Functions', 'Credentials_Dir': '/Users/mike/Develop/Projects/Code Notebook/Credentials', 'Rel_Pickes_Dir': '../.pickles', 'Pub_Data_Dir': \"'/Users/mike/Data/Public\", 'BQ_Service_Key': '/Users/mike/Develop/Conf/GCP Service Keys/mikecancell-development-0bcca41f8486.json'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check if the file exists and load the JSON file into a dictionary\n",
    "file_path = r'C:\\Users\\mike\\Develop\\Projects\\Code Notebook\\Credentials\\locations_conf.json'\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    print(locations_data)\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pickled Dataframes into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame from zip: crime_facts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 585000 entries, 0 to 584999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   dr_no           585000 non-null  object        \n",
      " 1   date_rptd       585000 non-null  datetime64[ns]\n",
      " 2   datetime_occ    585000 non-null  datetime64[ns]\n",
      " 3   rpt_dist_no     585000 non-null  int16         \n",
      " 4   vict_age        585000 non-null  int16         \n",
      " 5   lat             585000 non-null  float64       \n",
      " 6   lon             585000 non-null  float64       \n",
      " 7   area            585000 non-null  int16         \n",
      " 8   premis_cd       585000 non-null  int16         \n",
      " 9   crm_cd          585000 non-null  int16         \n",
      " 10  vict_sex        585000 non-null  category      \n",
      " 11  vict_descent    585000 non-null  category      \n",
      " 12  weapon_used_cd  585000 non-null  int16         \n",
      " 13  status          585000 non-null  category      \n",
      "dtypes: category(3), datetime64[ns](2), float64(2), int16(6), object(1)\n",
      "memory usage: 30.7+ MB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_area\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   fk_area    21 non-null     int16   \n",
      " 1   area_name  21 non-null     category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 363.0 bytes\n",
      "None\n",
      "Loaded DataFrame from zip: dim_crime\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139 entries, 0 to 138\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   fk_crm_cd    139 non-null    int16   \n",
      " 1   crm_cd_desc  139 non-null    category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 1.8 KB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_location\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52528 entries, 0 to 169383\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   lat                 52528 non-null  float64\n",
      " 1   lon                 52528 non-null  float64\n",
      " 2   geo_place_id        52528 non-null  object \n",
      " 3   geo_osm_type        52528 non-null  object \n",
      " 4   geo_osm_id          52528 non-null  object \n",
      " 5   geo_display_name    52528 non-null  object \n",
      " 6   geo_road            52416 non-null  object \n",
      " 7   geo_neighbourhood   8298 non-null   object \n",
      " 8   geo_suburb          35173 non-null  object \n",
      " 9   geo_city            52113 non-null  object \n",
      " 10  geo_state           52527 non-null  object \n",
      " 11  geo_ISO3166-2-lvl4  52527 non-null  object \n",
      " 12  geo_postcode        52364 non-null  object \n",
      " 13  geo_country         52527 non-null  object \n",
      " 14  geo_country_code    52527 non-null  object \n",
      " 15  geo_boundingbox     52528 non-null  object \n",
      "dtypes: float64(2), object(14)\n",
      "memory usage: 6.8+ MB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_premise\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 310 entries, 0 to 309\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   fk_premis_cd  310 non-null    int16   \n",
      " 1   premis_desc   302 non-null    category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 3.7 KB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_status\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   fk_status    6 non-null      category\n",
      " 1   status_desc  7 non-null      category\n",
      "dtypes: category(2)\n",
      "memory usage: 242.0 bytes\n",
      "None\n",
      "Loaded DataFrame from zip: dim_victim\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19 entries, 0 to 19\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   vict_descent  19 non-null     category\n",
      " 1   descent_desc  19 non-null     object  \n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 483.0+ bytes\n",
      "None\n",
      "Loaded DataFrame from zip: dim_weapon\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78 entries, 0 to 77\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   fk_weapon_used_cd  78 non-null     int16   \n",
      " 1   weapon_desc        77 non-null     category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 982.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "directory = locations_data['Rel_Pickes_Dir']\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.pkl') or filename.endswith('.pkl.zip'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        try:\n",
    "            if filename.endswith('.pkl.zip'):\n",
    "                with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                    for zip_info in zip_ref.infolist():\n",
    "                        if zip_info.filename.endswith('.pkl'):\n",
    "                            with zip_ref.open(zip_info) as file:\n",
    "                                df_name = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "                                globals()[df_name] = pd.DataFrame(pickle.load(file))\n",
    "                                print(f\"Loaded DataFrame from zip: {df_name}\")\n",
    "                                print(globals()[df_name].info())\n",
    "            else:\n",
    "                with open(filepath, 'rb') as file:\n",
    "                    df_name = os.path.splitext(filename)[0]\n",
    "                    globals()[df_name] = pd.DataFrame(pickle.load(file))\n",
    "                    print(f\"Loaded DataFrame: {df_name}\")\n",
    "                    print(globals()[df_name].info())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "# Now each pickle file is loaded into its own respective DataFrame variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a connection to Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame from zip: crime_facts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 585000 entries, 0 to 584999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   dr_no           585000 non-null  object        \n",
      " 1   date_rptd       585000 non-null  datetime64[ns]\n",
      " 2   datetime_occ    585000 non-null  datetime64[ns]\n",
      " 3   rpt_dist_no     585000 non-null  int16         \n",
      " 4   vict_age        585000 non-null  int16         \n",
      " 5   lat             585000 non-null  float64       \n",
      " 6   lon             585000 non-null  float64       \n",
      " 7   area            585000 non-null  int16         \n",
      " 8   premis_cd       585000 non-null  int16         \n",
      " 9   crm_cd          585000 non-null  int16         \n",
      " 10  vict_sex        585000 non-null  category      \n",
      " 11  vict_descent    585000 non-null  category      \n",
      " 12  weapon_used_cd  585000 non-null  int16         \n",
      " 13  status          585000 non-null  category      \n",
      "dtypes: category(3), datetime64[ns](2), float64(2), int16(6), object(1)\n",
      "memory usage: 30.7+ MB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_area\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   fk_area    21 non-null     int16   \n",
      " 1   area_name  21 non-null     category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 363.0 bytes\n",
      "None\n",
      "Loaded DataFrame from zip: dim_crime\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139 entries, 0 to 138\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   fk_crm_cd    139 non-null    int16   \n",
      " 1   crm_cd_desc  139 non-null    category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 1.8 KB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_location\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52528 entries, 0 to 169383\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   lat                 52528 non-null  float64\n",
      " 1   lon                 52528 non-null  float64\n",
      " 2   geo_place_id        52528 non-null  object \n",
      " 3   geo_osm_type        52528 non-null  object \n",
      " 4   geo_osm_id          52528 non-null  object \n",
      " 5   geo_display_name    52528 non-null  object \n",
      " 6   geo_road            52416 non-null  object \n",
      " 7   geo_neighbourhood   8298 non-null   object \n",
      " 8   geo_suburb          35173 non-null  object \n",
      " 9   geo_city            52113 non-null  object \n",
      " 10  geo_state           52527 non-null  object \n",
      " 11  geo_ISO3166-2-lvl4  52527 non-null  object \n",
      " 12  geo_postcode        52364 non-null  object \n",
      " 13  geo_country         52527 non-null  object \n",
      " 14  geo_country_code    52527 non-null  object \n",
      " 15  geo_boundingbox     52528 non-null  object \n",
      "dtypes: float64(2), object(14)\n",
      "memory usage: 6.8+ MB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_premise\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 310 entries, 0 to 309\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   fk_premis_cd  310 non-null    int16   \n",
      " 1   premis_desc   302 non-null    category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 3.7 KB\n",
      "None\n",
      "Loaded DataFrame from zip: dim_status\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   fk_status    6 non-null      category\n",
      " 1   status_desc  7 non-null      category\n",
      "dtypes: category(2)\n",
      "memory usage: 242.0 bytes\n",
      "None\n",
      "Loaded DataFrame from zip: dim_victim\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19 entries, 0 to 19\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   vict_descent  19 non-null     category\n",
      " 1   descent_desc  19 non-null     object  \n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 483.0+ bytes\n",
      "None\n",
      "Loaded DataFrame from zip: dim_weapon\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78 entries, 0 to 77\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   fk_weapon_used_cd  78 non-null     int16   \n",
      " 1   weapon_desc        77 non-null     category\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 982.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to the service account key file\n",
    "key_path = locations_data['BQ_Service_Key']\n",
    "\n",
    "# Create credentials using the service account key file\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Create a BigQuery client using the credentials\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "# Test the connection by listing datasets\n",
    "datasets = list(client.list_datasets())\n",
    "if datasets:\n",
    "    print(\"Datasets in project {}:\".format(client.project))\n",
    "    for dataset in datasets:\n",
    "        print(\"\\t{}\".format(dataset.dataset_id))\n",
    "else:\n",
    "    print(\"{} project does not contain any datasets.\".format(client.project))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset to Store the Tables (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project mikecancell-development:\n",
      "\tDatasets\n",
      "\tVC_data_job_postings_data_api\n",
      "\tuber_data\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset ID\n",
    "dataset_id = \"{}.Datasets\".format(client.project)\n",
    "\n",
    "# Check if the dataset already exists\n",
    "try:\n",
    "\tclient.get_dataset(dataset_id)  # Make an API request.\n",
    "\tprint(\"Dataset {} already exists.\".format(dataset_id))\n",
    "except Exception:\n",
    "\t# Construct a full Dataset object to send to the API\n",
    "\tdataset = bigquery.Dataset(dataset_id)\n",
    "\n",
    "\t# Specify the geographic location where the dataset should reside\n",
    "\tdataset.location = \"US\"\n",
    "\n",
    "\t# Send the dataset to the API for creation\n",
    "\tdataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "\n",
    "\tprint(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Tables to the Clould"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Mapping Dict between the DFs and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "schema_mappings = []\n",
    "\n",
    "for df_name, table_name in table_names.items():\n",
    "    for column in dataframes[df_name].columns:\n",
    "        field_type = 'STRING'\n",
    "        if dataframes[df_name][column].dtype.name == 'datetime64[ns]':\n",
    "            field_type = 'TIMESTAMP'\n",
    "        elif dataframes[df_name][column].dtype.name == 'float64':\n",
    "            field_type = 'FLOAT'\n",
    "        elif dataframes[df_name][column].dtype.name in ['int64', 'int16']:\n",
    "            field_type = 'INTEGER'\n",
    "        \n",
    "        description = column_descriptions.get(df_name, {}).get(column, f\"Description for {column}\")\n",
    "        \n",
    "        schema_mappings.append({\n",
    "            'dataframe': df_name,\n",
    "            'table_name': table_name,\n",
    "            'column_name': column,\n",
    "            'data_type': field_type,\n",
    "            'description': description\n",
    "        })\n",
    "\n",
    "schema_mappings.extend([\n",
    "    {\n",
    "        'dataframe': 'dim_area',\n",
    "        'table_name': 'LA_Crime_dim_area',\n",
    "        'columns': [\n",
    "            {'column_name': 'fk_area', 'data_type': 'INT64', 'description': 'Area Code'},\n",
    "            {'column_name': 'area_name', 'data_type': 'STRING', 'description': 'Area Name'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'dim_crime',\n",
    "        'table_name': 'LA_Crime_dim_crime',\n",
    "        'columns': [\n",
    "            {'column_name': 'fk_crm_cd', 'data_type': 'INT64', 'description': 'Crime Code'},\n",
    "            {'column_name': 'crm_cd_desc', 'data_type': 'STRING', 'description': 'Crime Description'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'dim_location',\n",
    "        'table_name': 'LA_Crime_dim_location',\n",
    "        'columns': [\n",
    "            {'column_name': 'lat'               , 'data_type': 'FLOAT64', 'description': 'Latitude'},\n",
    "            {'column_name': 'lon'               , 'data_type': 'FLOAT64', 'description': 'Longitude'},\n",
    "            {'column_name': 'geo_place_id'      , 'data_type': 'INT64', 'description': 'Geo Place ID'},\n",
    "            {'column_name': 'geo_osm_type'      , 'data_type': 'STRING' , 'description': 'Geo OSM Type'},\n",
    "            {'column_name': 'geo_osm_id'        , 'data_type': 'INT64', 'description': 'Geo OSM ID'},\n",
    "            {'column_name': 'geo_display_name'  , 'data_type': 'STRING' , 'description': 'Geo Display Name'},\n",
    "            {'column_name': 'geo_road'          , 'data_type': 'STRING' , 'description': 'Geo Road'},\n",
    "            {'column_name': 'geo_neighbourhood' , 'data_type': 'STRING' , 'description': 'Geo Neighbourhood'},\n",
    "            {'column_name': 'geo_suburb'        , 'data_type': 'STRING' , 'description': 'Geo Suburb'},\n",
    "            {'column_name': 'geo_city'          , 'data_type': 'STRING' , 'description': 'Geo City'},\n",
    "            {'column_name': 'geo_state'         , 'data_type': 'STRING' , 'description': 'Geo State'},\n",
    "            {'column_name': 'geo_ISO3166-2-lvl4', 'data_type': 'STRING' , 'description': 'Geo ISO3166-2 Level 4'},\n",
    "            {'column_name': 'geo_postcode'      , 'data_type': 'STRING' , 'description': 'Geo Postcode'},\n",
    "            {'column_name': 'geo_country'       , 'data_type': 'STRING' , 'description': 'Geo Country'},\n",
    "            {'column_name': 'geo_country_code'  , 'data_type': 'STRING' , 'description': 'Geo Country Code'},\n",
    "            {'column_name': 'geo_boundingbox'   , 'data_type': 'STRING' , 'description': 'Geo Bounding Box'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'dim_premise',\n",
    "        'table_name': 'LA_Crime_dim_premise',\n",
    "        'columns': [\n",
    "            {'column_name': 'fk_premis_cd'      , 'data_type': 'INT64', 'description': 'Premise Code'},\n",
    "            {'column_name': 'premis_desc'       , 'data_type': 'STRING'  , 'description': 'Premise Description'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'dim_status',\n",
    "        'table_name': 'LA_Crime_dim_status',\n",
    "        'columns': [\n",
    "            {'column_name': 'fk_status'     , 'data_type': 'STRING', 'description': 'Status Code'},\n",
    "            {'column_name': 'status_desc'   , 'data_type': 'STRING', 'description': 'Status Description'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'dim_victim',\n",
    "        'table_name': 'LA_Crime_dim_victim',\n",
    "        'columns': [\n",
    "            {'column_name': 'vict_descent', 'data_type': 'STRING', 'description': 'Victim Descent'},\n",
    "            {'column_name': 'descent_desc', 'data_type': 'STRING', 'description': 'Descent Description'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'dim_weapon',\n",
    "        'table_name': 'LA_Crime_dim_weapon',\n",
    "        'columns': [\n",
    "            {'column_name': 'fk_weapon_used_cd' , 'data_type': 'INT64', 'description': 'Weapon Used Code'},\n",
    "            {'column_name': 'weapon_desc'       , 'data_type': 'STRING'  , 'description': 'Weapon Description'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'dataframe': 'crime_facts',\n",
    "        'table_name': 'LA_Crime_crime_facts',\n",
    "        'columns': [\n",
    "            {'column_name': 'dr_no'         , 'data_type': 'STRING'  , 'description': 'DR Number'},\n",
    "            {'column_name': 'date_rptd'     , 'data_type': 'DATE'    , 'description': 'Date Reported'},\n",
    "            {'column_name': 'datetime_occ'  , 'data_type': 'DATETIME', 'description': 'Date and Time of Occurrence'},\n",
    "            {'column_name': 'rpt_dist_no'   , 'data_type': 'INT64', 'description': 'Report District Number'},\n",
    "            {'column_name': 'vict_age'      , 'data_type': 'INT64', 'description': 'Victim Age'},\n",
    "            {'column_name': 'lat'           , 'data_type': 'FLOAT'   , 'description': 'Latitude'},\n",
    "            {'column_name': 'lon'           , 'data_type': 'FLOAT'   , 'description': 'Longitude'},\n",
    "            {'column_name': 'area'          , 'data_type': 'INT64', 'description': 'Area'},\n",
    "            {'column_name': 'premis_cd'     , 'data_type': 'INT64', 'description': 'Premise Code'},\n",
    "            {'column_name': 'crm_cd'        , 'data_type': 'INT64', 'description': 'Crime Code'},\n",
    "            {'column_name': 'vict_sex'      , 'data_type': 'STRING'  , 'description': 'Victim Sex'},\n",
    "            {'column_name': 'vict_descent'  , 'data_type': 'STRING'  , 'description': 'Victim Descent'},\n",
    "            {'column_name': 'weapon_used_cd', 'data_type': 'INT64', 'description': 'Weapon Used Code'},\n",
    "            {'column_name': 'status'        , 'data_type': 'STRING'  , 'description': 'Status'}\n",
    "        ]\n",
    "    }\n",
    "])\n",
    "\n",
    "#pprint.pprint(schema_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Empty Schemas in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create empty tables in BigQuery with schema descriptions\n",
    "for mapping in schema_mappings:\n",
    "    table_id = f\"{client.project}.{dataset_id}.{mapping['table_name']}\"\n",
    "    \n",
    "    # Define the schema with descriptions\n",
    "    schema = []\n",
    "    if 'columns' in mapping:\n",
    "        for column_info in mapping['columns']:\n",
    "            schema_field = bigquery.SchemaField(\n",
    "                column_info['column_name'],\n",
    "                column_info['data_type'],\n",
    "                mode='NULLABLE',\n",
    "                description=column_info['description']\n",
    "            )\n",
    "            schema.append(schema_field)\n",
    "    else:\n",
    "        for column in dataframes[mapping['dataframe']].columns:\n",
    "            field_type = 'STRING'\n",
    "            if dataframes[mapping['dataframe']][column].dtype.name == 'datetime64[ns]':\n",
    "                field_type = 'TIMESTAMP'\n",
    "            elif dataframes[mapping['dataframe']][column].dtype.name == 'float64':\n",
    "                field_type = 'FLOAT'\n",
    "            elif dataframes[mapping['dataframe']][column].dtype.name in ['int64', 'int16']:\n",
    "                field_type = 'INTEGER'\n",
    "            \n",
    "            description = column_descriptions.get(mapping['dataframe'], {}).get(column, f\"Description for {column}\")\n",
    "            \n",
    "            schema_field = bigquery.SchemaField(\n",
    "                column,\n",
    "                field_type,\n",
    "                mode='NULLABLE',\n",
    "                description=description\n",
    "            )\n",
    "            schema.append(schema_field)\n",
    "    \n",
    "    # Create a table object with the schema\n",
    "    table = bigquery.Table(table_id, schema=schema)\n",
    "    \n",
    "    # Create or update the table in BigQuery\n",
    "    table = client.create_table(table, exists_ok=True)\n",
    "    print(f\"Created table {table_id} with schema descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Load the Frame Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "\n",
    "# Load the data into the BigQuery tables\n",
    "for mapping in schema_mappings:\n",
    "    table_id = f\"{client.project}.{dataset_id}.{mapping['table_name']}\"\n",
    "    \n",
    "    # Load the data into the table using pandas_gbq\n",
    "    pandas_gbq.to_gbq(dataframes[mapping['dataframe']], table_id, project_id=client.project, if_exists='replace', credentials=credentials)\n",
    "    print(f\"Loaded data into table {table_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the Tables to Save Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_area: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_area\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_crime: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_crime\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_location: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_location\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_premise: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_premise\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_status: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_status\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_victim: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_victim\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_weapon: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_dim_weapon\n",
      "Error deleting table mikecancell-development.mikecancell-development.Datasets.LA_Crime_crime_facts: table_id must be a fully-qualified ID in standard SQL format, e.g., \"project.dataset.table_id\", got mikecancell-development.mikecancell-development.Datasets.LA_Crime_crime_facts\n"
     ]
    }
   ],
   "source": [
    "# Define dataset_id\n",
    "dataset_id = \"{}.Datasets\".format(client.project)\n",
    "\n",
    "# Define table_names dictionary\n",
    "table_names = {\n",
    "    'dim_area': 'LA_Crime_dim_area',\n",
    "    'dim_crime': 'LA_Crime_dim_crime',\n",
    "    'dim_location': 'LA_Crime_dim_location',\n",
    "    'dim_premise': 'LA_Crime_dim_premise',\n",
    "    'dim_status': 'LA_Crime_dim_status',\n",
    "    'dim_victim': 'LA_Crime_dim_victim',\n",
    "    'dim_weapon': 'LA_Crime_dim_weapon',\n",
    "    'crime_facts': 'LA_Crime_crime_facts'\n",
    "}\n",
    "\n",
    "# Delete tables in BigQuery\n",
    "for table_name in table_names.values():\n",
    "    table_id = f\"{client.project}.{dataset_id}.{table_name}\"\n",
    "    try:\n",
    "        client.delete_table(table_id)  # Make an API request.\n",
    "        print(f\"Deleted table {table_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting table {table_id}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
