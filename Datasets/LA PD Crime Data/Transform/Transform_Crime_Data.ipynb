{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Conf and Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Directory Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Common_Funcs_Dir': '/Users/mike/Develop/Projects/Code Notebook/Common/Functions', 'Credentials_Dir': '/Users/mike/Develop/Projects/Code Notebook/Credentials', 'Rel_Pickes_Dir': '../.pickles', 'Pub_Data_Dir': \"'/Users/mike/Data/Public\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check if the file exists and load the JSON file into a dictionary\n",
    "file_path = r'C:\\Users\\mike\\Develop\\Projects\\Code Notebook\\Credentials\\locations_conf.json'\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    print(locations_data)\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Common Funcs Dir into the Sys Path\n",
    "This appears to be required bc the Funcs are .py files vs .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(locations_data['Common_Funcs_Dir'])\n",
    "from func_Load_Data_to_Frame import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Source Data to a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "source_file = 'LAPD_Crime_Data.json.zip'\n",
    "source_path = os.path.join(locations_data['Pub_Data_Dir'].strip(\"'\"), source_file)\n",
    "df = pd.read_json(source_path, compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Schmema Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published Schema:\n",
    "https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Schema in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 585000 entries, 0 to 584999\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   dr_no           585000 non-null  int64  \n",
      " 1   date_rptd       585000 non-null  object \n",
      " 2   date_occ        585000 non-null  object \n",
      " 3   time_occ        585000 non-null  int64  \n",
      " 4   area            585000 non-null  int64  \n",
      " 5   area_name       585000 non-null  object \n",
      " 6   rpt_dist_no     585000 non-null  int64  \n",
      " 7   part_1_2        585000 non-null  int64  \n",
      " 8   crm_cd          585000 non-null  int64  \n",
      " 9   crm_cd_desc     585000 non-null  object \n",
      " 10  mocodes         491719 non-null  object \n",
      " 11  vict_age        585000 non-null  int64  \n",
      " 12  vict_sex        496186 non-null  object \n",
      " 13  vict_descent    496179 non-null  object \n",
      " 14  premis_cd       584990 non-null  float64\n",
      " 15  premis_desc     584585 non-null  object \n",
      " 16  weapon_used_cd  175921 non-null  float64\n",
      " 17  weapon_desc     175921 non-null  object \n",
      " 18  status          584999 non-null  object \n",
      " 19  status_desc     585000 non-null  object \n",
      " 20  crm_cd_1        584993 non-null  float64\n",
      " 21  location        585000 non-null  object \n",
      " 22  lat             585000 non-null  float64\n",
      " 23  lon             585000 non-null  float64\n",
      " 24  cross_street    80715 non-null   object \n",
      " 25  crm_cd_2        35797 non-null   float64\n",
      " 26  crm_cd_3        1172 non-null    float64\n",
      " 27  crm_cd_4        29 non-null      float64\n",
      "dtypes: float64(8), int64(7), object(13)\n",
      "memory usage: 125.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show schema\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Align the Data Types using the Published Schema @\n",
    "https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the DR # (Div of Records Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    22-05-06019\n",
      "1    22-08-05315\n",
      "2    22-14-05638\n",
      "3    22-21-05108\n",
      "4    22-12-05693\n",
      "Name: dr_no, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert dr_no to a formatted string and update in place\n",
    "df['dr_no'] = df['dr_no'].apply(lambda x: f\"{str(x)[:2]}-{str(x)[2:4]}-{str(x)[4:]}\")\n",
    "\n",
    "# Display the type and head of the dr_no column\n",
    "print(df['dr_no'].dtype)\n",
    "print(df['dr_no'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Date Reported to a Date in format YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_rptd   date_occ\n",
      "0 2022-02-01 2020-02-01\n",
      "1 2022-02-01 2020-01-01\n",
      "2 2022-02-01 2020-09-01\n",
      "3 2022-02-01 2021-11-29\n",
      "4 2022-02-01 2021-12-21\n",
      "date_rptd    datetime64[ns]\n",
      "date_occ     datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "df['date_rptd'] = pd.to_datetime(df['date_rptd'])\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'])\n",
    "\n",
    "# Display the updated DataFrame with the new formatted date_rptd and date_occ columns\n",
    "print(df[['date_rptd', 'date_occ']].head())\n",
    "print(df[['date_rptd', 'date_occ']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Date Occurred and Time Occ into a single Timestamp and remove the orinal Time Occ col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         datetime_occ\n",
      "0 2020-02-01 12:00:00\n",
      "1 2020-01-01 12:00:00\n",
      "2 2020-09-01 14:25:00\n",
      "3 2021-11-29 12:00:00\n",
      "4 2021-12-21 18:00:00\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Combine date_occ and time_occ into a single datetime column\n",
    "df['datetime_occ'] = pd.to_datetime(df['date_occ'].dt.strftime('%Y-%m-%d') + ' ' + df['time_occ'].astype(str).str.zfill(4).str[:2] + ':' + df['time_occ'].astype(str).str.zfill(4).str[2:] + ':00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Drop the original time_occ and date_occ columns\n",
    "df.drop(columns=['time_occ', 'date_occ'], inplace=True)\n",
    "\n",
    "# Reorder columns to place datetime_occ in the original position of time_occ\n",
    "cols = df.columns.tolist()\n",
    "time_occ_index = cols.index('datetime_occ')\n",
    "cols.insert(3, cols.pop(time_occ_index))\n",
    "df = df[cols]\n",
    "\n",
    "# Display the updated DataFrame with the modified datetime_occ column\n",
    "print(df[['datetime_occ']].head())\n",
    "# Display the data type of the datetime_occ column\n",
    "print(df['datetime_occ'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Category Type Cols to Category types for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtype\n",
    "categorical_columns = ['area_name', 'crm_cd_desc', 'mocodes', 'vict_sex', 'vict_descent', 'premis_desc', 'weapon_desc', 'status', 'status_desc', 'location', 'cross_street']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Various Codes to Short Ints for space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area              int16\n",
      "rpt_dist_no       int16\n",
      "part_1_2          int16\n",
      "crm_cd            int16\n",
      "vict_age          int16\n",
      "premis_cd         int16\n",
      "weapon_used_cd    int16\n",
      "crm_cd_1          int16\n",
      "crm_cd_2          int16\n",
      "crm_cd_3          int16\n",
      "crm_cd_4          int16\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Recheck the integer columns as some may have changed and convert to a short int\n",
    "integer_columns = ['area', 'rpt_dist_no', 'part_1_2', 'crm_cd', 'vict_age', 'premis_cd', 'weapon_used_cd', 'crm_cd_1', 'crm_cd_2', 'crm_cd_3', 'crm_cd_4']\n",
    "for col in integer_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int16')\n",
    "\n",
    "# Display the columns and their data types\n",
    "print(df[integer_columns].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Lat and Lon Cols to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat    float64\n",
      "lon    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert latitude and longitude to float64\n",
    "df['lat'] = df['lat'].astype('float64')\n",
    "df['lon'] = df['lon'].astype('float64')\n",
    "\n",
    "# Verify changes\n",
    "print(df[['lat', 'lon']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the df into Dims and Facts\n",
    "See Schema here:\n",
    "https://lucid.app/lucidspark/a6f7a7bf-63d8-4aa7-ac61-6caa235ac916/edit?invitationId=inv_43e7079e-9d82-4f94-8907-0b93e812a852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_area         int16\n",
      "area_name    category\n",
      "dtype: object\n",
      "   fk_area    area_name\n",
      "0        5       Harbor\n",
      "1        8      West LA\n",
      "2       14      Pacific\n",
      "3       21      Topanga\n",
      "4       12  77th Street\n"
     ]
    }
   ],
   "source": [
    "# Create dimension tables\n",
    "dim_area = (\n",
    "    df[['area', 'area_name']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'area': 'fk_area'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_area.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_area.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fk_crm_cd                                      crm_cd_desc\n",
      "0        627          CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT\n",
      "1        236            INTIMATE PARTNER - AGGRAVATED ASSAULT\n",
      "2        354                                THEFT OF IDENTITY\n",
      "3        649                 DOCUMENT FORGERY / STOLEN FELONY\n",
      "4        420  THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)\n"
     ]
    }
   ],
   "source": [
    "dim_crime = (\n",
    "    df[['crm_cd', 'crm_cd_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'crm_cd': 'fk_crm_cd'})\n",
    ")\n",
    "# Display a few rows of the dimension table\n",
    "print(dim_crime.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Victim Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_sex    category\n",
      "sex_desc      object\n",
      "dtype: object\n",
      "  vict_sex sex_desc\n",
      "0        M     Male\n",
      "1        F   Female\n",
      "2        X  UNKNOWN\n",
      "4        H  UNKNOWN\n"
     ]
    }
   ],
   "source": [
    "dim_victim_sex = (\n",
    "    df[['vict_sex']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Set any missing data to 'X'\n",
    "dim_victim_sex['vict_sex'] = dim_victim_sex['vict_sex'].fillna('X')\n",
    "\n",
    "# Add sex_desc column\n",
    "dim_victim_sex['sex_desc'] = dim_victim_sex['vict_sex'].map({\n",
    "    'M': 'Male',\n",
    "    'F': 'Female',\n",
    "    'X': 'UNKNOWN',\n",
    "    'H': 'UNKNOWN'\n",
    "})\n",
    "\n",
    "# Drop duplicates\n",
    "dim_victim_sex = dim_victim_sex.drop_duplicates()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "dim_victim_sex = dim_victim_sex.dropna()\n",
    "\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_victim_sex.dtypes)\n",
    "print(dim_victim_sex.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Victim Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_descent    category\n",
      "descent_desc      object\n",
      "dtype: object\n",
      "   vict_descent                    descent_desc\n",
      "0             H          Hispanic/Latin/Mexican\n",
      "1             W                           White\n",
      "2             X                         Unknown\n",
      "4             B                           Black\n",
      "5             O                           Other\n",
      "6             A                     Other Asian\n",
      "7             F                        Filipino\n",
      "8             C                         Chinese\n",
      "9             V                      Vietnamese\n",
      "10            K                          Korean\n",
      "11            J                        Japanese\n",
      "12            S                          Samoan\n",
      "13            I  American Indian/Alaskan Native\n",
      "14            P                Pacific Islander\n",
      "15            Z                    Asian Indian\n",
      "16            L                         Laotian\n",
      "17            G                       Guamanian\n",
      "18            D                       Cambodian\n",
      "19            U                        Hawaiian\n"
     ]
    }
   ],
   "source": [
    "dim_victim = (\n",
    "    df[['vict_descent']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Set any missing data to 'X'\n",
    "dim_victim['vict_descent'] = dim_victim['vict_descent'].fillna('X')\n",
    "\n",
    "# Add descent_desc column\n",
    "dim_victim['descent_desc'] = dim_victim['vict_descent'].map({\n",
    "    'A': 'Other Asian',\n",
    "    'B': 'Black',\n",
    "    'C': 'Chinese',\n",
    "    'D': 'Cambodian',\n",
    "    'F': 'Filipino',\n",
    "    'G': 'Guamanian',\n",
    "    'H': 'Hispanic/Latin/Mexican',\n",
    "    'I': 'American Indian/Alaskan Native',\n",
    "    'J': 'Japanese',\n",
    "    'K': 'Korean',\n",
    "    'L': 'Laotian',\n",
    "    'O': 'Other',\n",
    "    'P': 'Pacific Islander',\n",
    "    'S': 'Samoan',\n",
    "    'U': 'Hawaiian',\n",
    "    'V': 'Vietnamese',\n",
    "    'W': 'White',\n",
    "    'X': 'Unknown',\n",
    "    'Z': 'Asian Indian'\n",
    "})\n",
    "\n",
    "# Drop duplicates\n",
    "dim_victim = dim_victim.drop_duplicates()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "dim_victim = dim_victim.dropna()\n",
    "\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_victim.dtypes)\n",
    "print(dim_victim.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Premises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_premis_cd       int16\n",
      "premis_desc     category\n",
      "dtype: object\n",
      "   fk_premis_cd                                   premis_desc\n",
      "0           501                        SINGLE FAMILY DWELLING\n",
      "1           502  MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)\n",
      "2           222                                    LAUNDROMAT\n",
      "3           101                                        STREET\n",
      "4           108                                   PARKING LOT\n"
     ]
    }
   ],
   "source": [
    "dim_premise = (\n",
    "    df[['premis_cd', 'premis_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'premis_cd': 'fk_premis_cd'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_premise.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_premise.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_weapon_used_cd       int16\n",
      "weapon_desc          category\n",
      "dtype: object\n",
      "   fk_weapon_used_cd                                     weapon_desc\n",
      "0                400  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)\n",
      "1                  0                                             NaN\n",
      "2                503                         CAUSTIC CHEMICAL/POISON\n",
      "3                500                     UNKNOWN WEAPON/OTHER WEAPON\n",
      "4                205                                   KITCHEN KNIFE\n"
     ]
    }
   ],
   "source": [
    "dim_weapon = (\n",
    "    df[['weapon_used_cd', 'weapon_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'weapon_used_cd': 'fk_weapon_used_cd'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_weapon.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_weapon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_status      category\n",
      "status_desc    category\n",
      "dtype: object\n",
      "  fk_status   status_desc\n",
      "0        AO   Adult Other\n",
      "1        IC   Invest Cont\n",
      "2        AA  Adult Arrest\n",
      "3        JA    Juv Arrest\n",
      "4        JO     Juv Other\n"
     ]
    }
   ],
   "source": [
    "dim_status = (\n",
    "    df[['status', 'status_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'status': 'fk_status'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_status.dtypes)\n",
    "print(dim_status.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat                   float64\n",
      "lon                   float64\n",
      "geo_place_id           object\n",
      "geo_osm_type           object\n",
      "geo_osm_id             object\n",
      "geo_display_name       object\n",
      "geo_road               object\n",
      "geo_neighbourhood      object\n",
      "geo_suburb             object\n",
      "geo_city               object\n",
      "geo_state              object\n",
      "geo_ISO3166-2-lvl4     object\n",
      "geo_postcode           object\n",
      "geo_country            object\n",
      "geo_country_code       object\n",
      "geo_boundingbox        object\n",
      "dtype: object\n",
      "       lat       lon geo_place_id geo_osm_type geo_osm_id geo_display_name  \\\n",
      "0  33.8201 -118.3015         None         None       None             None   \n",
      "1  34.0326 -118.3941         None         None       None             None   \n",
      "2  33.9875 -118.4668         None         None       None             None   \n",
      "3  34.1707 -118.6565         None         None       None             None   \n",
      "4  33.9638 -118.2629         None         None       None             None   \n",
      "\n",
      "  geo_road geo_neighbourhood geo_suburb geo_city geo_state geo_ISO3166-2-lvl4  \\\n",
      "0     None              None       None     None      None               None   \n",
      "1     None              None       None     None      None               None   \n",
      "2     None              None       None     None      None               None   \n",
      "3     None              None       None     None      None               None   \n",
      "4     None              None       None     None      None               None   \n",
      "\n",
      "  geo_postcode geo_country geo_country_code geo_boundingbox  \n",
      "0         None        None             None            None  \n",
      "1         None        None             None            None  \n",
      "2         None        None             None            None  \n",
      "3         None        None             None            None  \n",
      "4         None        None             None            None  \n"
     ]
    }
   ],
   "source": [
    "dim_location = (\n",
    "    df[['lat', 'lon']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Add additional columns based on Schema at https://geocode.maps.co/reverse\n",
    "# This data will be added downstream in the ETL process\n",
    "dim_location['geo_place_id'] = None\n",
    "dim_location['geo_osm_type'] = None\n",
    "dim_location['geo_osm_id'] = None\n",
    "dim_location['geo_display_name'] = None\n",
    "dim_location['geo_road'] = None\n",
    "dim_location['geo_neighbourhood'] = None\n",
    "dim_location['geo_suburb'] = None\n",
    "dim_location['geo_city'] = None\n",
    "dim_location['geo_state'] = None\n",
    "dim_location['geo_ISO3166-2-lvl4'] = None\n",
    "dim_location['geo_postcode'] = None\n",
    "dim_location['geo_country'] = None\n",
    "dim_location['geo_country_code'] = None\n",
    "dim_location['geo_boundingbox'] = None\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_location.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 585000 entries, 0 to 584999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   dr_no           585000 non-null  object        \n",
      " 1   date_rptd       585000 non-null  datetime64[ns]\n",
      " 2   datetime_occ    585000 non-null  datetime64[ns]\n",
      " 3   rpt_dist_no     585000 non-null  int16         \n",
      " 4   vict_age        585000 non-null  int16         \n",
      " 5   lat             585000 non-null  float64       \n",
      " 6   lon             585000 non-null  float64       \n",
      " 7   area            585000 non-null  int16         \n",
      " 8   premis_cd       585000 non-null  int16         \n",
      " 9   crm_cd          585000 non-null  int16         \n",
      " 10  vict_sex        585000 non-null  category      \n",
      " 11  vict_descent    585000 non-null  category      \n",
      " 12  weapon_used_cd  585000 non-null  int16         \n",
      " 13  status          585000 non-null  category      \n",
      "dtypes: category(3), datetime64[ns](2), float64(2), int16(6), object(1)\n",
      "memory usage: 30.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr_no</th>\n",
       "      <th>date_rptd</th>\n",
       "      <th>datetime_occ</th>\n",
       "      <th>rpt_dist_no</th>\n",
       "      <th>vict_age</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area</th>\n",
       "      <th>premis_cd</th>\n",
       "      <th>crm_cd</th>\n",
       "      <th>vict_sex</th>\n",
       "      <th>vict_descent</th>\n",
       "      <th>weapon_used_cd</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-05-06019</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2020-02-01 12:00:00</td>\n",
       "      <td>507</td>\n",
       "      <td>12</td>\n",
       "      <td>33.8201</td>\n",
       "      <td>-118.3015</td>\n",
       "      <td>5</td>\n",
       "      <td>501</td>\n",
       "      <td>627</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>400</td>\n",
       "      <td>AO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-08-05315</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2020-01-01 12:00:00</td>\n",
       "      <td>898</td>\n",
       "      <td>31</td>\n",
       "      <td>34.0326</td>\n",
       "      <td>-118.3941</td>\n",
       "      <td>8</td>\n",
       "      <td>502</td>\n",
       "      <td>236</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>400</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-14-05638</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2020-09-01 14:25:00</td>\n",
       "      <td>1431</td>\n",
       "      <td>42</td>\n",
       "      <td>33.9875</td>\n",
       "      <td>-118.4668</td>\n",
       "      <td>14</td>\n",
       "      <td>501</td>\n",
       "      <td>354</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-21-05108</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2021-11-29 12:00:00</td>\n",
       "      <td>2161</td>\n",
       "      <td>89</td>\n",
       "      <td>34.1707</td>\n",
       "      <td>-118.6565</td>\n",
       "      <td>21</td>\n",
       "      <td>501</td>\n",
       "      <td>649</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-12-05693</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2021-12-21 18:00:00</td>\n",
       "      <td>1269</td>\n",
       "      <td>35</td>\n",
       "      <td>33.9638</td>\n",
       "      <td>-118.2629</td>\n",
       "      <td>12</td>\n",
       "      <td>222</td>\n",
       "      <td>236</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>400</td>\n",
       "      <td>AO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dr_no  date_rptd        datetime_occ  rpt_dist_no  vict_age      lat  \\\n",
       "0  22-05-06019 2022-02-01 2020-02-01 12:00:00          507        12  33.8201   \n",
       "1  22-08-05315 2022-02-01 2020-01-01 12:00:00          898        31  34.0326   \n",
       "2  22-14-05638 2022-02-01 2020-09-01 14:25:00         1431        42  33.9875   \n",
       "3  22-21-05108 2022-02-01 2021-11-29 12:00:00         2161        89  34.1707   \n",
       "4  22-12-05693 2022-02-01 2021-12-21 18:00:00         1269        35  33.9638   \n",
       "\n",
       "        lon  area  premis_cd  crm_cd vict_sex vict_descent  weapon_used_cd  \\\n",
       "0 -118.3015     5        501     627        M            H             400   \n",
       "1 -118.3941     8        502     236        F            H             400   \n",
       "2 -118.4668    14        501     354        M            W               0   \n",
       "3 -118.6565    21        501     649        F            W               0   \n",
       "4 -118.2629    12        222     236        F            H             400   \n",
       "\n",
       "  status  \n",
       "0     AO  \n",
       "1     IC  \n",
       "2     IC  \n",
       "3     IC  \n",
       "4     AO  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create fact table\n",
    "crime_facts = df[\n",
    "    [\n",
    "        # Unique Facts\n",
    "        'dr_no', 'date_rptd', 'datetime_occ', 'rpt_dist_no', 'vict_age', \n",
    "        # Dim Locations\n",
    "        'lat', 'lon', \n",
    "        # Dim Area\n",
    "        'area', \n",
    "        # Dim Premise\n",
    "        'premis_cd',\n",
    "        # Dim Crime\n",
    "        'crm_cd', \n",
    "        # Dim Victim Sex\n",
    "        'vict_sex', \n",
    "        # Dim Victim Descent\n",
    "        'vict_descent',\n",
    "        # Dim Weapon\n",
    "        'weapon_used_cd',\n",
    "        # Dim Status \n",
    "        'status'\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Handle missing data\n",
    "crime_facts['vict_sex'] = crime_facts['vict_sex'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "crime_facts['vict_descent'] = crime_facts['vict_descent'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "crime_facts['status'] = crime_facts['status'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "\n",
    "# Display schema and types\n",
    "print(crime_facts.info())\n",
    "\n",
    "# Display fact table\n",
    "display(crime_facts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Post Processes - Retrieve Geo Code into Location Dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Location Dim from the Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat       lon geo_place_id geo_osm_type geo_osm_id  \\\n",
      "0   33.8201 -118.3015    281393593          way   13356241   \n",
      "6   34.0326 -118.3941    284925955          way  165791832   \n",
      "7   33.9875 -118.4668    281444680          way  168954633   \n",
      "11  34.1707 -118.6565    285003597          way  402526611   \n",
      "12  33.9638 -118.2629    281472844          way  165899885   \n",
      "\n",
      "                                     geo_display_name               geo_road  \\\n",
      "0   Halldale Avenue, Los Angeles, California, 9050...        Halldale Avenue   \n",
      "6   South Canfield Avenue, Castle Heights, Los Ang...  South Canfield Avenue   \n",
      "7   Venice Way, Venice Canal Historic District, Ve...             Venice Way   \n",
      "11  Burbank Boulevard, Los Angeles, Los Angeles Co...      Burbank Boulevard   \n",
      "12  Stanford Avenue, Florence, Los Angeles, Los An...        Stanford Avenue   \n",
      "\n",
      "                 geo_neighbourhood geo_suburb     geo_city   geo_state  \\\n",
      "0                             None       None  Los Angeles  California   \n",
      "6                   Castle Heights       None  Los Angeles  California   \n",
      "7   Venice Canal Historic District     Venice  Los Angeles  California   \n",
      "11                            None       None  Los Angeles  California   \n",
      "12                            None   Florence  Los Angeles  California   \n",
      "\n",
      "   geo_ISO3166-2-lvl4 geo_postcode    geo_country geo_country_code  \\\n",
      "0               US-CA        90501  United States               us   \n",
      "6               US-CA        90034  United States               us   \n",
      "7               US-CA        90292  United States               us   \n",
      "11              US-CA        91307  United States               us   \n",
      "12              US-CA        90001  United States               us   \n",
      "\n",
      "                                      geo_boundingbox  \n",
      "0   ['33.819016', '33.8208781', '-118.3015108', '-...  \n",
      "6   ['34.0296448', '34.035801', '-118.3953219', '-...  \n",
      "7   ['33.9874163', '33.9875684', '-118.468556', '-...  \n",
      "11  ['34.1702241', '34.1712426', '-118.6575549', '...  \n",
      "12  ['33.9601434', '33.9747425', '-118.262981', '-...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Set the pickle file path\n",
    "pickle_file = 'dim_location.pkl'\n",
    "pickle_path = os.path.join(locations_data['Rel_Pickes_Dir'], pickle_file)\n",
    "\n",
    "# Check if the pickle file is zipped\n",
    "if os.path.exists(pickle_path + '.zip'):\n",
    "\twith zipfile.ZipFile(pickle_path + '.zip', 'r') as z:\n",
    "\t\twith z.open(pickle_file) as f:\n",
    "\t\t\tdim_location = pd.read_pickle(f)\n",
    "else:\n",
    "\t# Load the dimension table from the pickle file\n",
    "\ttry:\n",
    "\t\tdim_location = pd.read_pickle(pickle_path)\n",
    "\texcept FileNotFoundError:\n",
    "\t\tprint(\"Pickle file not found. Please ensure the file exists.\")\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Locations that need to be Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the df: 0\n"
     ]
    }
   ],
   "source": [
    "tmp_locs_to_be_processed = dim_location[dim_location['geo_place_id'].isnull()][['lat', 'lon']].drop_duplicates()\n",
    "print(f\"Number of records in the df: {len(tmp_locs_to_be_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'API_Key': '679e7xxxxx', 'Reverse_URL': 'https://geocode.maps.co/reverse', 'Max_Lookups': 50000, 'Rate_Limit_per_Sec': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Set the path for the JSON file\n",
    "credentials_dir = locations_data['Credentials_Dir']\n",
    "json_file_path = os.path.join(credentials_dir, 'geocode_api_key.json')\n",
    "\n",
    "# Read the credentials from the JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    api_key_data = json.load(f)\n",
    "\n",
    "geo_api_credentials = {\n",
    "    'API_Key': api_key_data['API_Key'],\n",
    "    'Reverse_URL': api_key_data['Reverse_URL'],\n",
    "    'Max_Lookups': api_key_data['Max_Lookups'],\n",
    "    'Rate_Limit_per_Sec': api_key_data['Rate_Limit_per_Sec']\n",
    "}\n",
    "\n",
    "# Mask the API key for security\n",
    "masked_key = geo_api_credentials['API_Key'][:5] + 'xxxxx'\n",
    "geo_api_credentials['API_Key'] = masked_key\n",
    "\n",
    "print(geo_api_credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the GeoCode API to Fetch Location Details using the Reverse Lookup from the Lat/Lon\n",
    "See https://geocode.maps.co/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Func for the Fetch\n",
    "This will be moved to Common Funcs Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def Fetch_Geo_Data(api_credentials, locations):\n",
    "    base_url = api_credentials['Reverse_URL']\n",
    "    api_key = api_credentials['API_Key']\n",
    "    max_lookups = api_credentials['Max_Lookups']\n",
    "    rate_limit_per_sec = api_credentials['Rate_Limit_per_Sec']\n",
    "    \n",
    "    geo_data = []\n",
    "    \n",
    "    for index, row in tqdm(locations.iterrows(), total=locations.shape[0], desc=\"Fetching Geo Data\"):\n",
    "        if len(geo_data) >= max_lookups:\n",
    "            print(\"Reached the maximum number of lookups for the day.\")\n",
    "            break\n",
    "        \n",
    "        params = {\n",
    "            'lat': row['lat'],\n",
    "            'lon': row['lon'],\n",
    "            'api_key': api_key\n",
    "        }\n",
    "        \n",
    "        attempts = 0\n",
    "        while attempts < 3:\n",
    "            try:\n",
    "                response = requests.get(base_url, params=params)\n",
    "                url = f\"{base_url}?lat={row['lat']}&lon={row['lon']}&api_key={api_key}\"\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    if 'place_id' not in response.json():\n",
    "                        print(f\"Response content for lat: {row['lat']}, lon: {row['lon']} - {response.json()}\")\n",
    "                    geo_data.append(response.json())\n",
    "                    break\n",
    "                else:\n",
    "                    attempts += 1\n",
    "                    time.sleep(rate_limit_per_sec)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                attempts += 1\n",
    "                time.sleep(rate_limit_per_sec)\n",
    "        \n",
    "        if attempts == 3:\n",
    "            print(f\"Failed to fetch data for lat: {row['lat']}, lon: {row['lon']} after 3 attempts.\")\n",
    "            geo_data.append(None)\n",
    "    \n",
    "    return geo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now call the Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Geo Data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "        lat       lon geo_place_id geo_osm_type geo_osm_id  \\\n",
      "0   33.8201 -118.3015    281393593          way   13356241   \n",
      "6   34.0326 -118.3941    284925955          way  165791832   \n",
      "7   33.9875 -118.4668    281444680          way  168954633   \n",
      "11  34.1707 -118.6565    285003597          way  402526611   \n",
      "12  33.9638 -118.2629    281472844          way  165899885   \n",
      "\n",
      "                                     geo_display_name               geo_road  \\\n",
      "0   Halldale Avenue, Los Angeles, California, 9050...        Halldale Avenue   \n",
      "6   South Canfield Avenue, Castle Heights, Los Ang...  South Canfield Avenue   \n",
      "7   Venice Way, Venice Canal Historic District, Ve...             Venice Way   \n",
      "11  Burbank Boulevard, Los Angeles, Los Angeles Co...      Burbank Boulevard   \n",
      "12  Stanford Avenue, Florence, Los Angeles, Los An...        Stanford Avenue   \n",
      "\n",
      "                 geo_neighbourhood geo_suburb     geo_city   geo_state  \\\n",
      "0                             None       None  Los Angeles  California   \n",
      "6                   Castle Heights       None  Los Angeles  California   \n",
      "7   Venice Canal Historic District     Venice  Los Angeles  California   \n",
      "11                            None       None  Los Angeles  California   \n",
      "12                            None   Florence  Los Angeles  California   \n",
      "\n",
      "   geo_ISO3166-2-lvl4 geo_postcode    geo_country geo_country_code  \\\n",
      "0               US-CA        90501  United States               us   \n",
      "6               US-CA        90034  United States               us   \n",
      "7               US-CA        90292  United States               us   \n",
      "11              US-CA        91307  United States               us   \n",
      "12              US-CA        90001  United States               us   \n",
      "\n",
      "                                      geo_boundingbox  \n",
      "0   ['33.819016', '33.8208781', '-118.3015108', '-...  \n",
      "6   ['34.0296448', '34.035801', '-118.3953219', '-...  \n",
      "7   ['33.9874163', '33.9875684', '-118.468556', '-...  \n",
      "11  ['34.1702241', '34.1712426', '-118.6575549', '...  \n",
      "12  ['33.9601434', '33.9747425', '-118.262981', '-...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "geo_data = Fetch_Geo_Data(geo_api_credentials, tmp_locs_to_be_processed)\n",
    "print(geo_data[:5])\n",
    "# Update the dim_location DataFrame with the fetched geo data\n",
    "for i, data in enumerate(geo_data):\n",
    "    if data:\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_place_id'] = data.get('place_id')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_osm_type'] = data.get('osm_type')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_osm_id'] = data.get('osm_id')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_display_name'] = data.get('display_name')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_road'] = data.get('address', {}).get('road')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_neighbourhood'] = data.get('address', {}).get('neighbourhood')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_suburb'] = data.get('address', {}).get('suburb')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_city'] = data.get('address', {}).get('city')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_state'] = data.get('address', {}).get('state')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_ISO3166-2-lvl4'] = data.get('address', {}).get('ISO3166-2-lvl4')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_postcode'] = data.get('address', {}).get('postcode')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_country'] = data.get('address', {}).get('country')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_country_code'] = data.get('address', {}).get('country_code')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_boundingbox'] = data.get('boundingbox')\n",
    "\n",
    "# Display updated dim_location DataFrame\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle & Zip Dims, Facts for Downstream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "pickles_dir = locations_data['Rel_Pickes_Dir']\n",
    "os.makedirs(pickles_dir, exist_ok=True)\n",
    "\n",
    "# Define a list of the dimension and fact tables along with their filenames\n",
    "pickle_files = [\n",
    "    (dim_area, 'dim_area.pkl'),\n",
    "    (dim_crime, 'dim_crime.pkl'),\n",
    "    (dim_victim, 'dim_victim.pkl'),\n",
    "    (dim_premise, 'dim_premise.pkl'),\n",
    "    (dim_weapon, 'dim_weapon.pkl'),\n",
    "    (dim_status, 'dim_status.pkl'),\n",
    "    (dim_location, 'dim_location.pkl'),\n",
    "    (crime_facts, 'crime_facts.pkl')\n",
    "]\n",
    "\n",
    "# Use a while loop to pickle the tables\n",
    "i = 0\n",
    "while i < len(pickle_files):\n",
    "    df, filename = pickle_files[i]\n",
    "    pickle_path = os.path.join(pickles_dir, filename)\n",
    "    df.to_pickle(pickle_path)\n",
    "    \n",
    "    # Zip the pickle file\n",
    "    with zipfile.ZipFile(pickle_path + '.zip', 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "        z.write(pickle_path, filename)\n",
    "    \n",
    "    # Remove the uncompressed pickle file\n",
    "    os.remove(pickle_path)\n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
