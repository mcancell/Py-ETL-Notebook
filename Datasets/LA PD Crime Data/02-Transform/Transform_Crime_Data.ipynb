{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Conf and Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Directory Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Common_Funcs_Dir': '/Users/mike/Develop/Projects/Code Notebook/Common/Functions', 'Credentials_Dir': '/Users/mike/Develop/Projects/Code Notebook/Credentials', 'Rel_Pickes_Dir': '../.pickles', 'Pub_Data_Dir': \"'/Users/mike/Data/Public\", 'BQ_Service_Key': '/Users/mike/Develop/Conf/GCP Service Keys/mikecancell-development-0bcca41f8486.json'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check if the file exists and load the JSON file into a dictionary\n",
    "file_path = r'C:\\Users\\mike\\Develop\\Projects\\Code Notebook\\Credentials\\locations_conf.json'\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    print(locations_data)\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Common Funcs Dir into the Sys Path\n",
    "This appears to be required bc the Funcs are .py files vs .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(locations_data['Common_Funcs_Dir'])\n",
    "from func_Load_Data_to_Frame import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Source Data to a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dr_no                date_rptd                 date_occ  time_occ  \\\n",
      "0    1307355  2010-02-20T00:00:00.000  2010-02-20T00:00:00.000      1350   \n",
      "1   11401303  2010-09-13T00:00:00.000  2010-09-12T00:00:00.000        45   \n",
      "2   70309629  2010-08-09T00:00:00.000  2010-08-09T00:00:00.000      1515   \n",
      "3   90631215  2010-01-05T00:00:00.000  2010-01-05T00:00:00.000       150   \n",
      "4  100100501  2010-01-03T00:00:00.000  2010-01-02T00:00:00.000      2100   \n",
      "\n",
      "   area  area_name  rpt_dist_no  part_1_2  crm_cd  \\\n",
      "0    13     Newton         1385         2     900   \n",
      "1    14    Pacific         1485         2     740   \n",
      "2    13     Newton         1324         2     946   \n",
      "3     6  Hollywood          646         2     900   \n",
      "4     1    Central          176         1     122   \n",
      "\n",
      "                                         crm_cd_desc  ... crm_cd_1  \\\n",
      "0                           VIOLATION OF COURT ORDER  ...    900.0   \n",
      "1  VANDALISM - FELONY ($400 & OVER, ALL CHURCH VA...  ...    740.0   \n",
      "2                          OTHER MISCELLANEOUS CRIME  ...    946.0   \n",
      "3                           VIOLATION OF COURT ORDER  ...    900.0   \n",
      "4                                    RAPE, ATTEMPTED  ...    122.0   \n",
      "\n",
      "                                  location      lat       lon  \\\n",
      "0   300 E  GAGE                         AV  33.9825 -118.2695   \n",
      "1          SEPULVEDA                    BL  33.9599 -118.3962   \n",
      "2  1300 E  21ST                         ST  34.0224 -118.2524   \n",
      "3          CAHUENGA                     BL  34.1016 -118.3295   \n",
      "4          8TH                          ST  34.0387 -118.2488   \n",
      "\n",
      "                      cross_street weapon_used_cd  \\\n",
      "0                              NaN            NaN   \n",
      "1  MANCHESTER                   AV            NaN   \n",
      "2                              NaN            NaN   \n",
      "3  HOLLYWOOD                    BL          102.0   \n",
      "4  SAN PEDRO                    ST          400.0   \n",
      "\n",
      "                                      weapon_desc crm_cd_2  crm_cd_3 crm_cd_4  \n",
      "0                                             NaN      NaN       NaN      NaN  \n",
      "1                                             NaN      NaN       NaN      NaN  \n",
      "2                                             NaN      NaN       NaN      NaN  \n",
      "3                                        HAND GUN    998.0       NaN      NaN  \n",
      "4  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)      NaN       NaN      NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get all files matching the pattern\n",
    "source_pattern = os.path.join(locations_data['Pub_Data_Dir'].strip(\"'\"), 'LAPD_Crime_Data.json_*')\n",
    "source_files = glob.glob(source_pattern)\n",
    "\n",
    "# Load and concatenate all matching files into a single DataFrame\n",
    "df_list = [pd.read_json(file, compression='zip') for file in source_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Schmema Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published Schema:\n",
    "https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Schema in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3157000 entries, 0 to 3156999\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   dr_no           int64  \n",
      " 1   date_rptd       object \n",
      " 2   date_occ        object \n",
      " 3   time_occ        int64  \n",
      " 4   area            int64  \n",
      " 5   area_name       object \n",
      " 6   rpt_dist_no     int64  \n",
      " 7   part_1_2        int64  \n",
      " 8   crm_cd          int64  \n",
      " 9   crm_cd_desc     object \n",
      " 10  mocodes         object \n",
      " 11  vict_age        int64  \n",
      " 12  vict_sex        object \n",
      " 13  vict_descent    object \n",
      " 14  premis_cd       float64\n",
      " 15  premis_desc     object \n",
      " 16  status          object \n",
      " 17  status_desc     object \n",
      " 18  crm_cd_1        float64\n",
      " 19  location        object \n",
      " 20  lat             float64\n",
      " 21  lon             float64\n",
      " 22  cross_street    object \n",
      " 23  weapon_used_cd  float64\n",
      " 24  weapon_desc     object \n",
      " 25  crm_cd_2        float64\n",
      " 26  crm_cd_3        float64\n",
      " 27  crm_cd_4        float64\n",
      "dtypes: float64(8), int64(7), object(13)\n",
      "memory usage: 674.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show schema\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Align the Data Types using the Published Schema @\n",
    "https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the DR # (Div of Records Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0      13-07-355\n",
      "1     11-40-1303\n",
      "2     70-30-9629\n",
      "3     90-63-1215\n",
      "4    10-01-00501\n",
      "Name: dr_no, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert dr_no to a formatted string and update in place\n",
    "df['dr_no'] = df['dr_no'].apply(lambda x: f\"{str(x)[:2]}-{str(x)[2:4]}-{str(x)[4:]}\")\n",
    "\n",
    "# Display the type and head of the dr_no column\n",
    "print(df['dr_no'].dtype)\n",
    "print(df['dr_no'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Date Reported to a Date in format YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_rptd   date_occ\n",
      "0 2010-02-20 2010-02-20\n",
      "1 2010-09-13 2010-09-12\n",
      "2 2010-08-09 2010-08-09\n",
      "3 2010-01-05 2010-01-05\n",
      "4 2010-01-03 2010-01-02\n",
      "date_rptd    datetime64[ns]\n",
      "date_occ     datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "df['date_rptd'] = pd.to_datetime(df['date_rptd'])\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'])\n",
    "\n",
    "# Display the updated DataFrame with the new formatted date_rptd and date_occ columns\n",
    "print(df[['date_rptd', 'date_occ']].head())\n",
    "print(df[['date_rptd', 'date_occ']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Date Occurred and Time Occ into a single Timestamp and remove the orinal Time Occ col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         datetime_occ\n",
      "0 2010-02-20 13:50:00\n",
      "1 2010-09-12 00:45:00\n",
      "2 2010-08-09 15:15:00\n",
      "3 2010-01-05 01:50:00\n",
      "4 2010-01-02 21:00:00\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Combine date_occ and time_occ into a single datetime column\n",
    "df['datetime_occ'] = pd.to_datetime(df['date_occ'].dt.strftime('%Y-%m-%d') + ' ' + df['time_occ'].astype(str).str.zfill(4).str[:2] + ':' + df['time_occ'].astype(str).str.zfill(4).str[2:] + ':00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Drop the original time_occ and date_occ columns\n",
    "df.drop(columns=['time_occ', 'date_occ'], inplace=True)\n",
    "\n",
    "# Reorder columns to place datetime_occ in the original position of time_occ\n",
    "cols = df.columns.tolist()\n",
    "time_occ_index = cols.index('datetime_occ')\n",
    "cols.insert(3, cols.pop(time_occ_index))\n",
    "df = df[cols]\n",
    "\n",
    "# Display the updated DataFrame with the modified datetime_occ column\n",
    "print(df[['datetime_occ']].head())\n",
    "# Display the data type of the datetime_occ column\n",
    "print(df['datetime_occ'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Category Type Cols to Category types for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtype\n",
    "categorical_columns = ['area_name', 'crm_cd_desc', 'mocodes', 'vict_sex', 'vict_descent', 'premis_desc', 'weapon_desc', 'status', 'status_desc', 'location', 'cross_street']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Various Codes to Short Ints for space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area              int16\n",
      "rpt_dist_no       int16\n",
      "part_1_2          int16\n",
      "crm_cd            int16\n",
      "vict_age          int16\n",
      "premis_cd         int16\n",
      "weapon_used_cd    int16\n",
      "crm_cd_1          int16\n",
      "crm_cd_2          int16\n",
      "crm_cd_3          int16\n",
      "crm_cd_4          int16\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Recheck the integer columns as some may have changed and convert to a short int\n",
    "integer_columns = ['area', 'rpt_dist_no', 'part_1_2', 'crm_cd', 'vict_age', 'premis_cd', 'weapon_used_cd', 'crm_cd_1', 'crm_cd_2', 'crm_cd_3', 'crm_cd_4']\n",
    "for col in integer_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int16')\n",
    "\n",
    "# Display the columns and their data types\n",
    "print(df[integer_columns].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Lat and Lon Cols to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat    float64\n",
      "lon    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert latitude and longitude to float64\n",
    "df['lat'] = df['lat'].astype('float64')\n",
    "df['lon'] = df['lon'].astype('float64')\n",
    "\n",
    "# Verify changes\n",
    "print(df[['lat', 'lon']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the df into Dims and Facts\n",
    "See Schema here:\n",
    "https://lucid.app/lucidspark/a6f7a7bf-63d8-4aa7-ac61-6caa235ac916/edit?invitationId=inv_43e7079e-9d82-4f94-8907-0b93e812a852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_area         int16\n",
      "area_name    category\n",
      "dtype: object\n",
      "   fk_area  area_name\n",
      "0       13     Newton\n",
      "1       14    Pacific\n",
      "2        6  Hollywood\n",
      "3        1    Central\n",
      "4       11  Northeast\n"
     ]
    }
   ],
   "source": [
    "# Create dimension tables\n",
    "dim_area = (\n",
    "    df[['area', 'area_name']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'area': 'fk_area'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_area.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_area.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fk_crm_cd                                        crm_cd_desc\n",
      "0        900                           VIOLATION OF COURT ORDER\n",
      "1        740  VANDALISM - FELONY ($400 & OVER, ALL CHURCH VA...\n",
      "2        946                          OTHER MISCELLANEOUS CRIME\n",
      "3        122                                    RAPE, ATTEMPTED\n",
      "4        442           SHOPLIFTING - PETTY THEFT ($950 & UNDER)\n"
     ]
    }
   ],
   "source": [
    "dim_crime = (\n",
    "    df[['crm_cd', 'crm_cd_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'crm_cd': 'fk_crm_cd'})\n",
    ")\n",
    "# Display a few rows of the dimension table\n",
    "print(dim_crime.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Victim Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_sex    category\n",
      "sex_desc      object\n",
      "dtype: object\n",
      "  vict_sex sex_desc\n",
      "0        M     Male\n",
      "1        F   Female\n",
      "2        X  UNKNOWN\n",
      "4        H  UNKNOWN\n"
     ]
    }
   ],
   "source": [
    "dim_victim_sex = (\n",
    "    df[['vict_sex']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Set any missing data to 'X'\n",
    "dim_victim_sex['vict_sex'] = dim_victim_sex['vict_sex'].fillna('X')\n",
    "\n",
    "# Add sex_desc column\n",
    "dim_victim_sex['sex_desc'] = dim_victim_sex['vict_sex'].map({\n",
    "    'M': 'Male',\n",
    "    'F': 'Female',\n",
    "    'X': 'UNKNOWN',\n",
    "    'H': 'UNKNOWN'\n",
    "})\n",
    "\n",
    "# Drop duplicates\n",
    "dim_victim_sex = dim_victim_sex.drop_duplicates()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "dim_victim_sex = dim_victim_sex.dropna()\n",
    "\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_victim_sex.dtypes)\n",
    "print(dim_victim_sex.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Victim Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_descent    category\n",
      "descent_desc      object\n",
      "dtype: object\n",
      "   vict_descent                    descent_desc\n",
      "0             H          Hispanic/Latin/Mexican\n",
      "1             W                           White\n",
      "2             B                           Black\n",
      "3             A                     Other Asian\n",
      "4             O                           Other\n",
      "5             X                         Unknown\n",
      "6             K                          Korean\n",
      "8             I  American Indian/Alaskan Native\n",
      "9             J                        Japanese\n",
      "10            F                        Filipino\n",
      "11            C                         Chinese\n",
      "12            P                Pacific Islander\n",
      "13            V                      Vietnamese\n",
      "14            U                        Hawaiian\n",
      "15            G                       Guamanian\n",
      "16            D                       Cambodian\n",
      "17            S                          Samoan\n",
      "18            Z                    Asian Indian\n",
      "19            L                         Laotian\n"
     ]
    }
   ],
   "source": [
    "dim_victim = (\n",
    "    df[['vict_descent']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Set any missing data to 'X'\n",
    "dim_victim['vict_descent'] = dim_victim['vict_descent'].fillna('X')\n",
    "\n",
    "# Add descent_desc column\n",
    "dim_victim['descent_desc'] = dim_victim['vict_descent'].map({\n",
    "    'A': 'Other Asian',\n",
    "    'B': 'Black',\n",
    "    'C': 'Chinese',\n",
    "    'D': 'Cambodian',\n",
    "    'F': 'Filipino',\n",
    "    'G': 'Guamanian',\n",
    "    'H': 'Hispanic/Latin/Mexican',\n",
    "    'I': 'American Indian/Alaskan Native',\n",
    "    'J': 'Japanese',\n",
    "    'K': 'Korean',\n",
    "    'L': 'Laotian',\n",
    "    'O': 'Other',\n",
    "    'P': 'Pacific Islander',\n",
    "    'S': 'Samoan',\n",
    "    'U': 'Hawaiian',\n",
    "    'V': 'Vietnamese',\n",
    "    'W': 'White',\n",
    "    'X': 'Unknown',\n",
    "    'Z': 'Asian Indian'\n",
    "})\n",
    "\n",
    "# Drop duplicates\n",
    "dim_victim = dim_victim.drop_duplicates()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "dim_victim = dim_victim.dropna()\n",
    "\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_victim.dtypes)\n",
    "print(dim_victim.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Premises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_premis_cd       int16\n",
      "premis_desc     category\n",
      "dtype: object\n",
      "   fk_premis_cd             premis_desc\n",
      "0           501  SINGLE FAMILY DWELLING\n",
      "1           101                  STREET\n",
      "2           103                   ALLEY\n",
      "3           404        DEPARTMENT STORE\n",
      "4           710           OTHER PREMISE\n"
     ]
    }
   ],
   "source": [
    "dim_premise = (\n",
    "    df[['premis_cd', 'premis_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'premis_cd': 'fk_premis_cd'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_premise.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_premise.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_weapon_used_cd       int16\n",
      "weapon_desc          category\n",
      "dtype: object\n",
      "   fk_weapon_used_cd                                     weapon_desc\n",
      "0                  0                                             NaN\n",
      "1                102                                        HAND GUN\n",
      "2                400  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)\n",
      "3                500                     UNKNOWN WEAPON/OTHER WEAPON\n",
      "4                511                                   VERBAL THREAT\n"
     ]
    }
   ],
   "source": [
    "dim_weapon = (\n",
    "    df[['weapon_used_cd', 'weapon_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'weapon_used_cd': 'fk_weapon_used_cd'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_weapon.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_weapon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_status      category\n",
      "status_desc    category\n",
      "dtype: object\n",
      "  fk_status   status_desc\n",
      "0        AA  Adult Arrest\n",
      "1        IC   Invest Cont\n",
      "2        AO   Adult Other\n",
      "3        JA    Juv Arrest\n",
      "4        JO     Juv Other\n"
     ]
    }
   ],
   "source": [
    "dim_status = (\n",
    "    df[['status', 'status_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'status': 'fk_status'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_status.dtypes)\n",
    "print(dim_status.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat                   float64\n",
      "lon                   float64\n",
      "geo_place_id           object\n",
      "geo_osm_type           object\n",
      "geo_osm_id             object\n",
      "geo_display_name       object\n",
      "geo_road               object\n",
      "geo_neighbourhood      object\n",
      "geo_suburb             object\n",
      "geo_city               object\n",
      "geo_state              object\n",
      "geo_ISO3166-2-lvl4     object\n",
      "geo_postcode           object\n",
      "geo_country            object\n",
      "geo_country_code       object\n",
      "geo_boundingbox        object\n",
      "dtype: object\n",
      "       lat       lon geo_place_id geo_osm_type geo_osm_id geo_display_name  \\\n",
      "0  33.9825 -118.2695         None         None       None             None   \n",
      "1  33.9599 -118.3962         None         None       None             None   \n",
      "2  34.0224 -118.2524         None         None       None             None   \n",
      "3  34.1016 -118.3295         None         None       None             None   \n",
      "4  34.0387 -118.2488         None         None       None             None   \n",
      "\n",
      "  geo_road geo_neighbourhood geo_suburb geo_city geo_state geo_ISO3166-2-lvl4  \\\n",
      "0     None              None       None     None      None               None   \n",
      "1     None              None       None     None      None               None   \n",
      "2     None              None       None     None      None               None   \n",
      "3     None              None       None     None      None               None   \n",
      "4     None              None       None     None      None               None   \n",
      "\n",
      "  geo_postcode geo_country geo_country_code geo_boundingbox  \n",
      "0         None        None             None            None  \n",
      "1         None        None             None            None  \n",
      "2         None        None             None            None  \n",
      "3         None        None             None            None  \n",
      "4         None        None             None            None  \n"
     ]
    }
   ],
   "source": [
    "dim_location = (\n",
    "    df[['lat', 'lon']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Add additional columns based on Schema at https://geocode.maps.co/reverse\n",
    "# This data will be added downstream in the ETL process\n",
    "dim_location['geo_place_id'] = None\n",
    "dim_location['geo_osm_type'] = None\n",
    "dim_location['geo_osm_id'] = None\n",
    "dim_location['geo_display_name'] = None\n",
    "dim_location['geo_road'] = None\n",
    "dim_location['geo_neighbourhood'] = None\n",
    "dim_location['geo_suburb'] = None\n",
    "dim_location['geo_city'] = None\n",
    "dim_location['geo_state'] = None\n",
    "dim_location['geo_ISO3166-2-lvl4'] = None\n",
    "dim_location['geo_postcode'] = None\n",
    "dim_location['geo_country'] = None\n",
    "dim_location['geo_country_code'] = None\n",
    "dim_location['geo_boundingbox'] = None\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_location.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lat       lon block_fips county_fips county_name state_fips state_code  \\\n",
      "0  33.9825 -118.2695       None        None        None       None       None   \n",
      "1  33.9599 -118.3962       None        None        None       None       None   \n",
      "2  34.0224 -118.2524       None        None        None       None       None   \n",
      "3  34.1016 -118.3295       None        None        None       None       None   \n",
      "4  34.0387 -118.2488       None        None        None       None       None   \n",
      "\n",
      "  state_name block_pop_2020   amt  ...   bta   cma   eag   ivm   mea   mta  \\\n",
      "0       None           None  None  ...  None  None  None  None  None  None   \n",
      "1       None           None  None  ...  None  None  None  None  None  None   \n",
      "2       None           None  None  ...  None  None  None  None  None  None   \n",
      "3       None           None  None  ...  None  None  None  None  None  None   \n",
      "4       None           None  None  ...  None  None  None  None  None  None   \n",
      "\n",
      "    pea   rea   rpc   vpc  \n",
      "0  None  None  None  None  \n",
      "1  None  None  None  None  \n",
      "2  None  None  None  None  \n",
      "3  None  None  None  None  \n",
      "4  None  None  None  None  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "dim_census = (\n",
    "    df[['lat', 'lon']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Add additional columns based on the provided JSON schema\n",
    "dim_census['block_fips'] = None\n",
    "dim_census['county_fips'] = None\n",
    "dim_census['county_name'] = None\n",
    "dim_census['state_fips'] = None\n",
    "dim_census['state_code'] = None\n",
    "dim_census['state_name'] = None\n",
    "dim_census['block_pop_2020'] = None\n",
    "dim_census['amt'] = None\n",
    "dim_census['bea'] = None\n",
    "dim_census['bta'] = None\n",
    "dim_census['cma'] = None\n",
    "dim_census['eag'] = None\n",
    "dim_census['ivm'] = None\n",
    "dim_census['mea'] = None\n",
    "dim_census['mta'] = None\n",
    "dim_census['pea'] = None\n",
    "dim_census['rea'] = None\n",
    "dim_census['rpc'] = None\n",
    "dim_census['vpc'] = None\n",
    "\n",
    "# Display the updated DataFrame with the new columns\n",
    "print(dim_census.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3157000 entries, 0 to 3156999\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   dr_no           object        \n",
      " 1   date_rptd       datetime64[ns]\n",
      " 2   datetime_occ    datetime64[ns]\n",
      " 3   rpt_dist_no     int16         \n",
      " 4   vict_age        int16         \n",
      " 5   lat             float64       \n",
      " 6   lon             float64       \n",
      " 7   area            int16         \n",
      " 8   premis_cd       int16         \n",
      " 9   crm_cd          int16         \n",
      " 10  vict_sex        category      \n",
      " 11  vict_descent    category      \n",
      " 12  weapon_used_cd  int16         \n",
      " 13  status          category      \n",
      " 14  mon_rptd        datetime64[ns]\n",
      " 15  mon_occ         datetime64[ns]\n",
      "dtypes: category(3), datetime64[ns](4), float64(2), int16(6), object(1)\n",
      "memory usage: 213.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dr_no",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_rptd",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "datetime_occ",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "rpt_dist_no",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "vict_age",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "area",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "premis_cd",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "crm_cd",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "vict_sex",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "vict_descent",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "weapon_used_cd",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "status",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "mon_rptd",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "mon_occ",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "450e33b8-4e4c-447a-a42b-4d603719900e",
       "rows": [
        [
         "0",
         "13-07-355",
         "2010-02-20 00:00:00",
         "2010-02-20 13:50:00",
         "1385",
         "48",
         "33.9825",
         "-118.2695",
         "13",
         "501",
         "900",
         "M",
         "H",
         "0",
         "AA",
         "2010-02-01 00:00:00",
         "2010-02-01 00:00:00"
        ],
        [
         "1",
         "11-40-1303",
         "2010-09-13 00:00:00",
         "2010-09-12 00:45:00",
         "1485",
         "0",
         "33.9599",
         "-118.3962",
         "14",
         "101",
         "740",
         "M",
         "W",
         "0",
         "IC",
         "2010-09-01 00:00:00",
         "2010-09-01 00:00:00"
        ],
        [
         "2",
         "70-30-9629",
         "2010-08-09 00:00:00",
         "2010-08-09 15:15:00",
         "1324",
         "0",
         "34.0224",
         "-118.2524",
         "13",
         "103",
         "946",
         "M",
         "H",
         "0",
         "IC",
         "2010-08-01 00:00:00",
         "2010-08-01 00:00:00"
        ],
        [
         "3",
         "90-63-1215",
         "2010-01-05 00:00:00",
         "2010-01-05 01:50:00",
         "646",
         "47",
         "34.1016",
         "-118.3295",
         "6",
         "101",
         "900",
         "F",
         "W",
         "102",
         "IC",
         "2010-01-01 00:00:00",
         "2010-01-01 00:00:00"
        ],
        [
         "4",
         "10-01-00501",
         "2010-01-03 00:00:00",
         "2010-01-02 21:00:00",
         "176",
         "47",
         "34.0387",
         "-118.2488",
         "1",
         "103",
         "122",
         "F",
         "H",
         "400",
         "IC",
         "2010-01-01 00:00:00",
         "2010-01-01 00:00:00"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr_no</th>\n",
       "      <th>date_rptd</th>\n",
       "      <th>datetime_occ</th>\n",
       "      <th>rpt_dist_no</th>\n",
       "      <th>vict_age</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area</th>\n",
       "      <th>premis_cd</th>\n",
       "      <th>crm_cd</th>\n",
       "      <th>vict_sex</th>\n",
       "      <th>vict_descent</th>\n",
       "      <th>weapon_used_cd</th>\n",
       "      <th>status</th>\n",
       "      <th>mon_rptd</th>\n",
       "      <th>mon_occ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13-07-355</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>2010-02-20 13:50:00</td>\n",
       "      <td>1385</td>\n",
       "      <td>48</td>\n",
       "      <td>33.9825</td>\n",
       "      <td>-118.2695</td>\n",
       "      <td>13</td>\n",
       "      <td>501</td>\n",
       "      <td>900</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>AA</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>2010-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-40-1303</td>\n",
       "      <td>2010-09-13</td>\n",
       "      <td>2010-09-12 00:45:00</td>\n",
       "      <td>1485</td>\n",
       "      <td>0</td>\n",
       "      <td>33.9599</td>\n",
       "      <td>-118.3962</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>740</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>2010-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70-30-9629</td>\n",
       "      <td>2010-08-09</td>\n",
       "      <td>2010-08-09 15:15:00</td>\n",
       "      <td>1324</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0224</td>\n",
       "      <td>-118.2524</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>946</td>\n",
       "      <td>M</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>2010-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90-63-1215</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>2010-01-05 01:50:00</td>\n",
       "      <td>646</td>\n",
       "      <td>47</td>\n",
       "      <td>34.1016</td>\n",
       "      <td>-118.3295</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>900</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>102</td>\n",
       "      <td>IC</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-01-00501</td>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>2010-01-02 21:00:00</td>\n",
       "      <td>176</td>\n",
       "      <td>47</td>\n",
       "      <td>34.0387</td>\n",
       "      <td>-118.2488</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>122</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>400</td>\n",
       "      <td>IC</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dr_no  date_rptd        datetime_occ  rpt_dist_no  vict_age      lat  \\\n",
       "0    13-07-355 2010-02-20 2010-02-20 13:50:00         1385        48  33.9825   \n",
       "1   11-40-1303 2010-09-13 2010-09-12 00:45:00         1485         0  33.9599   \n",
       "2   70-30-9629 2010-08-09 2010-08-09 15:15:00         1324         0  34.0224   \n",
       "3   90-63-1215 2010-01-05 2010-01-05 01:50:00          646        47  34.1016   \n",
       "4  10-01-00501 2010-01-03 2010-01-02 21:00:00          176        47  34.0387   \n",
       "\n",
       "        lon  area  premis_cd  crm_cd vict_sex vict_descent  weapon_used_cd  \\\n",
       "0 -118.2695    13        501     900        M            H               0   \n",
       "1 -118.3962    14        101     740        M            W               0   \n",
       "2 -118.2524    13        103     946        M            H               0   \n",
       "3 -118.3295     6        101     900        F            W             102   \n",
       "4 -118.2488     1        103     122        F            H             400   \n",
       "\n",
       "  status   mon_rptd    mon_occ  \n",
       "0     AA 2010-02-01 2010-02-01  \n",
       "1     IC 2010-09-01 2010-09-01  \n",
       "2     IC 2010-08-01 2010-08-01  \n",
       "3     IC 2010-01-01 2010-01-01  \n",
       "4     IC 2010-01-01 2010-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create fact table\n",
    "crime_facts = df[\n",
    "    [\n",
    "        # Unique Facts\n",
    "        'dr_no', 'date_rptd', 'datetime_occ', 'rpt_dist_no', 'vict_age', \n",
    "        # Dim Locations\n",
    "        'lat', 'lon', \n",
    "        # Dim Area\n",
    "        'area', \n",
    "        # Dim Premise\n",
    "        'premis_cd',\n",
    "        # Dim Crime\n",
    "        'crm_cd', \n",
    "        # Dim Victim Sex\n",
    "        'vict_sex', \n",
    "        # Dim Victim Descent\n",
    "        'vict_descent',\n",
    "        # Dim Weapon\n",
    "        'weapon_used_cd',\n",
    "        # Dim Status \n",
    "        'status'\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Add new columns for the first day of the month\n",
    "crime_facts['mon_rptd'] = crime_facts['date_rptd'].dt.to_period('M').dt.to_timestamp()\n",
    "crime_facts['mon_occ'] = crime_facts['datetime_occ'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Handle missing data\n",
    "crime_facts['vict_sex'] = crime_facts['vict_sex'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "crime_facts['vict_descent'] = crime_facts['vict_descent'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "crime_facts['status'] = crime_facts['status'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "\n",
    "# Display schema and types\n",
    "print(crime_facts.info())\n",
    "\n",
    "# Display fact table\n",
    "display(crime_facts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Post Processes - Retrieve Geo Code into Location Dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Location Dim from the Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat       lon geo_place_id geo_osm_type geo_osm_id  \\\n",
      "0   33.8201 -118.3015    281393593          way   13356241   \n",
      "6   34.0326 -118.3941    284925955          way  165791832   \n",
      "7   33.9875 -118.4668    281444680          way  168954633   \n",
      "11  34.1707 -118.6565    285003597          way  402526611   \n",
      "12  33.9638 -118.2629    281472844          way  165899885   \n",
      "\n",
      "                                     geo_display_name               geo_road  \\\n",
      "0   Halldale Avenue, Los Angeles, California, 9050...        Halldale Avenue   \n",
      "6   South Canfield Avenue, Castle Heights, Los Ang...  South Canfield Avenue   \n",
      "7   Venice Way, Venice Canal Historic District, Ve...             Venice Way   \n",
      "11  Burbank Boulevard, Los Angeles, Los Angeles Co...      Burbank Boulevard   \n",
      "12  Stanford Avenue, Florence, Los Angeles, Los An...        Stanford Avenue   \n",
      "\n",
      "                 geo_neighbourhood geo_suburb     geo_city   geo_state  \\\n",
      "0                             None       None  Los Angeles  California   \n",
      "6                   Castle Heights       None  Los Angeles  California   \n",
      "7   Venice Canal Historic District     Venice  Los Angeles  California   \n",
      "11                            None       None  Los Angeles  California   \n",
      "12                            None   Florence  Los Angeles  California   \n",
      "\n",
      "   geo_ISO3166-2-lvl4 geo_postcode    geo_country geo_country_code  \\\n",
      "0               US-CA        90501  United States               us   \n",
      "6               US-CA        90034  United States               us   \n",
      "7               US-CA        90292  United States               us   \n",
      "11              US-CA        91307  United States               us   \n",
      "12              US-CA        90001  United States               us   \n",
      "\n",
      "                                      geo_boundingbox  \n",
      "0   ['33.819016', '33.8208781', '-118.3015108', '-...  \n",
      "6   ['34.0296448', '34.035801', '-118.3953219', '-...  \n",
      "7   ['33.9874163', '33.9875684', '-118.468556', '-...  \n",
      "11  ['34.1702241', '34.1712426', '-118.6575549', '...  \n",
      "12  ['33.9601434', '33.9747425', '-118.262981', '-...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Set the pickle file path\n",
    "pickle_file = 'dim_location.pkl'\n",
    "pickle_path = os.path.join(locations_data['Rel_Pickes_Dir'], pickle_file)\n",
    "\n",
    "# Check if the pickle file is zipped\n",
    "if os.path.exists(pickle_path + '.zip'):\n",
    "\twith zipfile.ZipFile(pickle_path + '.zip', 'r') as z:\n",
    "\t\twith z.open(pickle_file) as f:\n",
    "\t\t\tdim_location = pd.read_pickle(f)\n",
    "else:\n",
    "\t# Load the dimension table from the pickle file\n",
    "\ttry:\n",
    "\t\tdim_location = pd.read_pickle(pickle_path)\n",
    "\texcept FileNotFoundError:\n",
    "\t\tprint(\"Pickle file not found. Please ensure the file exists.\")\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Census Dim from the Pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lat       lon       block_fips county_fips         county_name  \\\n",
      "0  34.0210 -118.3002  060372095102002       06037  Los Angeles County   \n",
      "1  34.1576 -118.4387  060372933041015       06037  Los Angeles County   \n",
      "2  34.0820 -118.2130  060371835201010       06037  Los Angeles County   \n",
      "3  34.0642 -118.2771  060372267011001       06037  Los Angeles County   \n",
      "4  34.0536 -118.2788  060372079021009       06037  Los Angeles County   \n",
      "\n",
      "  state_fips state_code  state_name block_pop_2020     amt  ...     bta  \\\n",
      "0         06         CA  California            587  AMT006  ...  BTA262   \n",
      "1         06         CA  California            257  AMT006  ...  BTA262   \n",
      "2         06         CA  California            302  AMT006  ...  BTA262   \n",
      "3         06         CA  California            144  AMT006  ...  BTA262   \n",
      "4         06         CA  California             28  AMT006  ...  BTA262   \n",
      "\n",
      "      cma     eag     ivm     mea     mta     pea     rea     rpc     vpc  \n",
      "0  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "1  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "2  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "3  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "4  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Set the pickle file path\n",
    "pickle_file = 'dim_census.pkl'\n",
    "pickle_path = os.path.join(locations_data['Rel_Pickes_Dir'], pickle_file)\n",
    "\n",
    "# Check if the pickle file is zipped\n",
    "if os.path.exists(pickle_path + '.zip'):\n",
    "\twith zipfile.ZipFile(pickle_path + '.zip', 'r') as z:\n",
    "\t\twith z.open(pickle_file) as f:\n",
    "\t\t\tdim_census = pd.read_pickle(f)\n",
    "else:\n",
    "\t# Load the dimension table from the pickle file\n",
    "\ttry:\n",
    "\t\tdim_census = pd.read_pickle(pickle_path)\n",
    "\texcept FileNotFoundError:\n",
    "\t\tprint(\"Pickle file not found. Please ensure the file exists.\")\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(dim_census.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Locations that need to be Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the df: 0\n"
     ]
    }
   ],
   "source": [
    "tmp_locs_to_be_processed = dim_location[dim_location['geo_place_id'].isnull()][['lat', 'lon']].drop_duplicates()\n",
    "print(f\"Number of records in the df: {len(tmp_locs_to_be_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Census Tracts that need to be Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the df: 0\n"
     ]
    }
   ],
   "source": [
    "tmp_census_block_fips_to_be_processed = dim_census[dim_census['block_fips'].isnull()][['lat', 'lon']].drop_duplicates()\n",
    "print(f\"Number of records in the df: {len(tmp_census_block_fips_to_be_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the API Credentials for GeoCode Rev Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'API_Key': '679e7xxxxx', 'Reverse_URL': 'https://geocode.maps.co/reverse', 'Max_Lookups': 50000, 'Rate_Limit_per_Sec': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Set the path for the JSON file\n",
    "credentials_dir = locations_data['Credentials_Dir']\n",
    "json_file_path = os.path.join(credentials_dir, 'geocode_api_key.json')\n",
    "\n",
    "# Read the credentials from the JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    api_key_data = json.load(f)\n",
    "\n",
    "geo_api_credentials = {\n",
    "    'API_Key': api_key_data['API_Key'],\n",
    "    'Reverse_URL': api_key_data['Reverse_URL'],\n",
    "    'Max_Lookups': api_key_data['Max_Lookups'],\n",
    "    'Rate_Limit_per_Sec': api_key_data['Rate_Limit_per_Sec']\n",
    "}\n",
    "\n",
    "# Mask the API key for security\n",
    "masked_key = geo_api_credentials['API_Key'][:5] + 'xxxxx'\n",
    "geo_api_credentials['API_Key'] = masked_key\n",
    "\n",
    "print(geo_api_credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the GeoCode API to Fetch Location Details using the Reverse Lookup from the Lat/Lon\n",
    "See https://geocode.maps.co/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Func for the Fetch\n",
    "This will be moved to Common Funcs Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def Fetch_Geo_Data(api_credentials, locations):\n",
    "    base_url = api_credentials['Reverse_URL']\n",
    "    api_key = api_credentials['API_Key']\n",
    "    max_lookups = api_credentials['Max_Lookups']\n",
    "    rate_limit_per_sec = api_credentials['Rate_Limit_per_Sec']\n",
    "    \n",
    "    geo_data = []\n",
    "    \n",
    "    for index, row in tqdm(locations.iterrows(), total=locations.shape[0], desc=\"Fetching Geo Data\"):\n",
    "        if len(geo_data) >= max_lookups:\n",
    "            print(\"Reached the maximum number of lookups for the day.\")\n",
    "            break\n",
    "        \n",
    "        params = {\n",
    "            'lat': row['lat'],\n",
    "            'lon': row['lon'],\n",
    "            'api_key': api_key\n",
    "        }\n",
    "        \n",
    "        attempts = 0\n",
    "        while attempts < 3:\n",
    "            try:\n",
    "                response = requests.get(base_url, params=params)\n",
    "                url = f\"{base_url}?lat={row['lat']}&lon={row['lon']}&api_key={api_key}\"\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    if 'place_id' not in response.json():\n",
    "                        print(f\"Response content for lat: {row['lat']}, lon: {row['lon']} - {response.json()}\")\n",
    "                    geo_data.append(response.json())\n",
    "                    break\n",
    "                else:\n",
    "                    attempts += 1\n",
    "                    time.sleep(rate_limit_per_sec)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                attempts += 1\n",
    "                time.sleep(rate_limit_per_sec)\n",
    "        \n",
    "        if attempts == 3:\n",
    "            print(f\"Failed to fetch data for lat: {row['lat']}, lon: {row['lon']} after 3 attempts.\")\n",
    "            geo_data.append(None)\n",
    "    \n",
    "    return geo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now call the Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Geo Data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "        lat       lon geo_place_id geo_osm_type geo_osm_id  \\\n",
      "0   33.8201 -118.3015    281393593          way   13356241   \n",
      "6   34.0326 -118.3941    284925955          way  165791832   \n",
      "7   33.9875 -118.4668    281444680          way  168954633   \n",
      "11  34.1707 -118.6565    285003597          way  402526611   \n",
      "12  33.9638 -118.2629    281472844          way  165899885   \n",
      "\n",
      "                                     geo_display_name               geo_road  \\\n",
      "0   Halldale Avenue, Los Angeles, California, 9050...        Halldale Avenue   \n",
      "6   South Canfield Avenue, Castle Heights, Los Ang...  South Canfield Avenue   \n",
      "7   Venice Way, Venice Canal Historic District, Ve...             Venice Way   \n",
      "11  Burbank Boulevard, Los Angeles, Los Angeles Co...      Burbank Boulevard   \n",
      "12  Stanford Avenue, Florence, Los Angeles, Los An...        Stanford Avenue   \n",
      "\n",
      "                 geo_neighbourhood geo_suburb     geo_city   geo_state  \\\n",
      "0                             None       None  Los Angeles  California   \n",
      "6                   Castle Heights       None  Los Angeles  California   \n",
      "7   Venice Canal Historic District     Venice  Los Angeles  California   \n",
      "11                            None       None  Los Angeles  California   \n",
      "12                            None   Florence  Los Angeles  California   \n",
      "\n",
      "   geo_ISO3166-2-lvl4 geo_postcode    geo_country geo_country_code  \\\n",
      "0               US-CA        90501  United States               us   \n",
      "6               US-CA        90034  United States               us   \n",
      "7               US-CA        90292  United States               us   \n",
      "11              US-CA        91307  United States               us   \n",
      "12              US-CA        90001  United States               us   \n",
      "\n",
      "                                      geo_boundingbox  \n",
      "0   ['33.819016', '33.8208781', '-118.3015108', '-...  \n",
      "6   ['34.0296448', '34.035801', '-118.3953219', '-...  \n",
      "7   ['33.9874163', '33.9875684', '-118.468556', '-...  \n",
      "11  ['34.1702241', '34.1712426', '-118.6575549', '...  \n",
      "12  ['33.9601434', '33.9747425', '-118.262981', '-...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "geo_data = Fetch_Geo_Data(geo_api_credentials, tmp_locs_to_be_processed)\n",
    "print(geo_data[:5])\n",
    "# Update the dim_location DataFrame with the fetched geo data\n",
    "for i, data in enumerate(geo_data):\n",
    "    if data:\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_place_id'] = data.get('place_id')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_osm_type'] = data.get('osm_type')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_osm_id'] = data.get('osm_id')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_display_name'] = data.get('display_name')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_road'] = data.get('address', {}).get('road')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_neighbourhood'] = data.get('address', {}).get('neighbourhood')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_suburb'] = data.get('address', {}).get('suburb')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_city'] = data.get('address', {}).get('city')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_state'] = data.get('address', {}).get('state')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_ISO3166-2-lvl4'] = data.get('address', {}).get('ISO3166-2-lvl4')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_postcode'] = data.get('address', {}).get('postcode')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_country'] = data.get('address', {}).get('country')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_country_code'] = data.get('address', {}).get('country_code')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_boundingbox'] = data.get('boundingbox')\n",
    "\n",
    "# Display updated dim_location DataFrame\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the FCC API to Fetch Census Details from the Lat/Lon\n",
    "See https://geo.fcc.gov/api/census/#!/area/get_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Func for the Fetch\n",
    "This will be moved to Common Funcs Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def fetch_census_data_for_location(row):\n",
    "    base_url = \"https://geo.fcc.gov/api/census/area\"\n",
    "    census_year = 2020\n",
    "    format_type = \"json\"\n",
    "    \n",
    "    params = {\n",
    "        'lat': row['lat'],\n",
    "        'lon': row['lon'],\n",
    "        'censusYear': census_year,\n",
    "        'format': format_type\n",
    "    }\n",
    "    \n",
    "    attempts = 0\n",
    "    while attempts < 2:\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                response_data = response.json()\n",
    "                with open('../logs/census_fetch_debug.log', 'a') as log_file:\n",
    "                    log_file.write(f\"Response data for lat: {row['lat']}, lon: {row['lon']} - {response_data}\\n\")\n",
    "                return response_data\n",
    "            else:\n",
    "                attempts += 1\n",
    "                time.sleep(1)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            attempts += 1\n",
    "            time.sleep(1/2)\n",
    "    \n",
    "    with open('../logs/census_fetch_errors.log', 'a') as log_file:\n",
    "        log_file.write(f\"Failed to fetch data for lat: {row['lat']}, lon: {row['lon']} after 2 attempts.\\n\")\n",
    "    return None\n",
    "\n",
    "def Fetch_Census_Data(locations, max_responses, max_workers=10):\n",
    "    census_data = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(fetch_census_data_for_location, row): index for index, row in locations.iterrows()}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching Census Data\"):\n",
    "            if len(census_data) >= max_responses:\n",
    "                print(\"Max number of responses reached. Stopping data fetch.\")\n",
    "                break\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                census_data.append(result)\n",
    "                if len(census_data) >= max_responses:\n",
    "                    print(\"Max number of responses reached. Stopping data fetch.\")\n",
    "                    break\n",
    "\n",
    "    # Cancel remaining futures if max_responses is reached\n",
    "    for future in futures:\n",
    "        if not future.done():\n",
    "            future.cancel()\n",
    "    \n",
    "    return census_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now call the Func Fetch_Census_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Census Data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lat       lon       block_fips county_fips         county_name  \\\n",
      "0  34.0210 -118.3002  060372095102002       06037  Los Angeles County   \n",
      "1  34.1576 -118.4387  060372933041015       06037  Los Angeles County   \n",
      "2  34.0820 -118.2130  060371835201010       06037  Los Angeles County   \n",
      "3  34.0642 -118.2771  060372267011001       06037  Los Angeles County   \n",
      "4  34.0536 -118.2788  060372079021009       06037  Los Angeles County   \n",
      "\n",
      "  state_fips state_code  state_name block_pop_2020     amt  ...     bta  \\\n",
      "0         06         CA  California            587  AMT006  ...  BTA262   \n",
      "1         06         CA  California            257  AMT006  ...  BTA262   \n",
      "2         06         CA  California            302  AMT006  ...  BTA262   \n",
      "3         06         CA  California            144  AMT006  ...  BTA262   \n",
      "4         06         CA  California             28  AMT006  ...  BTA262   \n",
      "\n",
      "      cma     eag     ivm     mea     mta     pea     rea     rpc     vpc  \n",
      "0  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "1  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "2  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "3  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "4  CMA002  EAG706  IVM002  MEA044  MTA002  PEA002  REA006  RPC005  VPC006  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "census_data = Fetch_Census_Data(tmp_census_block_fips_to_be_processed, max_responses=100000, max_workers=20)\n",
    "\n",
    "# Update the dim_census DataFrame with the fetched census data\n",
    "for i, data in enumerate(census_data):\n",
    "    if data and 'results' in data and data['results']:\n",
    "        result = data['results'][0]\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'block_fips'] = result.get('block_fips')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'county_fips'] = result.get('county_fips')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'county_name'] = result.get('county_name')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'state_fips'] = result.get('state_fips')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'state_code'] = result.get('state_code')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'state_name'] = result.get('state_name')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'block_pop_2020'] = result.get('block_pop_2020')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'amt'] = result.get('amt')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'bea'] = result.get('bea')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'bta'] = result.get('bta')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'cma'] = result.get('cma')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'eag'] = result.get('eag')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'ivm'] = result.get('ivm')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'mea'] = result.get('mea')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'mta'] = result.get('mta')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'pea'] = result.get('pea')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'rea'] = result.get('rea')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'rpc'] = result.get('rpc')\n",
    "        dim_census.at[tmp_census_block_fips_to_be_processed.index[i], 'vpc'] = result.get('vpc')\n",
    "\n",
    "# Display updated dim_census DataFrame\n",
    "print(dim_census.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle & Zip Dims, Facts for Downstream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "pickles_dir = locations_data['Rel_Pickes_Dir']\n",
    "os.makedirs(pickles_dir, exist_ok=True)\n",
    "\n",
    "# Define a list of the dimension and fact tables along with their filenames\n",
    "pickle_files = [\n",
    "    (dim_area, 'dim_area.pkl'),\n",
    "    (dim_crime, 'dim_crime.pkl'),\n",
    "    (dim_victim, 'dim_victim.pkl'),\n",
    "    (dim_premise, 'dim_premise.pkl'),\n",
    "    (dim_weapon, 'dim_weapon.pkl'),\n",
    "    (dim_status, 'dim_status.pkl'),\n",
    "    (dim_location, 'dim_location.pkl'),\n",
    "    (dim_census, 'dim_census.pkl'),\n",
    "    (crime_facts, 'crime_facts.pkl')\n",
    "]\n",
    "\n",
    "# Use a while loop to pickle the tables\n",
    "i = 0\n",
    "while i < len(pickle_files):\n",
    "    df, filename = pickle_files[i]\n",
    "    pickle_path = os.path.join(pickles_dir, filename)\n",
    "    df.to_pickle(pickle_path)\n",
    "    \n",
    "    # Zip the pickle file\n",
    "    with zipfile.ZipFile(pickle_path + '.zip', 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "        z.write(pickle_path, filename)\n",
    "    \n",
    "    # Remove the uncompressed pickle file\n",
    "    os.remove(pickle_path)\n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
