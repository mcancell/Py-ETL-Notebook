{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Conf and Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Directory Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Common_Funcs_Dir': '/Users/mike/Develop/Projects/Code Notebook/Common/Functions', 'Credentials_Dir': '/Users/mike/Develop/Projects/Code Notebook/Credentials', 'Rel_Pickes_Dir': '../.pickles', 'Pub_Data_Dir': \"'/Users/mike/Data/Public\", 'BQ_Service_Key': '/Users/mike/Develop/Conf/GCP Service Keys/mikecancell-development-0bcca41f8486.json'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check if the file exists and load the JSON file into a dictionary\n",
    "file_path = r'C:\\Users\\mike\\Develop\\Projects\\Code Notebook\\Credentials\\locations_conf.json'\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    print(locations_data)\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Common Funcs Dir into the Sys Path\n",
    "This appears to be required bc the Funcs are .py files vs .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(locations_data['Common_Funcs_Dir'])\n",
    "from func_Load_Data_to_Frame import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Source Data to a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "source_file = 'LAPD_Crime_Data.json.zip'\n",
    "source_path = os.path.join(locations_data['Pub_Data_Dir'].strip(\"'\"), source_file)\n",
    "df = pd.read_json(source_path, compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Schmema Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published Schema:\n",
    "https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Schema in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972000 entries, 0 to 971999\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   dr_no           972000 non-null  int64  \n",
      " 1   date_rptd       972000 non-null  object \n",
      " 2   date_occ        972000 non-null  object \n",
      " 3   time_occ        972000 non-null  int64  \n",
      " 4   area            972000 non-null  int64  \n",
      " 5   area_name       972000 non-null  object \n",
      " 6   rpt_dist_no     972000 non-null  int64  \n",
      " 7   part_1_2        972000 non-null  int64  \n",
      " 8   crm_cd          972000 non-null  int64  \n",
      " 9   crm_cd_desc     972000 non-null  object \n",
      " 10  mocodes         823794 non-null  object \n",
      " 11  vict_age        972000 non-null  int64  \n",
      " 12  vict_sex        830565 non-null  object \n",
      " 13  vict_descent    830554 non-null  object \n",
      " 14  premis_cd       971984 non-null  float64\n",
      " 15  premis_desc     971427 non-null  object \n",
      " 16  status          971999 non-null  object \n",
      " 17  status_desc     972000 non-null  object \n",
      " 18  crm_cd_1        971989 non-null  float64\n",
      " 19  location        972000 non-null  object \n",
      " 20  lat             972000 non-null  float64\n",
      " 21  lon             972000 non-null  float64\n",
      " 22  crm_cd_2        66575 non-null   float64\n",
      " 23  cross_street    148252 non-null  object \n",
      " 24  weapon_used_cd  315018 non-null  float64\n",
      " 25  weapon_desc     315018 non-null  object \n",
      " 26  crm_cd_3        2226 non-null    float64\n",
      " 27  crm_cd_4        61 non-null      float64\n",
      "dtypes: float64(8), int64(7), object(13)\n",
      "memory usage: 207.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show schema\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Align the Data Types using the Published Schema @\n",
    "https://data.lacity.org/Public-Safety/Crime-Data-from-2020-to-Present/2nrs-mtv8/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the DR # (Div of Records Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    20-03-20258\n",
      "1    20-09-07217\n",
      "2    20-04-12582\n",
      "3    20-02-09713\n",
      "4    20-02-00759\n",
      "Name: dr_no, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert dr_no to a formatted string and update in place\n",
    "df['dr_no'] = df['dr_no'].apply(lambda x: f\"{str(x)[:2]}-{str(x)[2:4]}-{str(x)[4:]}\")\n",
    "\n",
    "# Display the type and head of the dr_no column\n",
    "print(df['dr_no'].dtype)\n",
    "print(df['dr_no'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Date Reported to a Date in format YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date_rptd   date_occ\n",
      "0 2020-11-11 2020-11-04\n",
      "1 2023-05-10 2020-03-10\n",
      "2 2020-09-09 2020-09-09\n",
      "3 2020-05-03 2020-05-02\n",
      "4 2020-07-07 2020-07-07\n",
      "date_rptd    datetime64[ns]\n",
      "date_occ     datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "df['date_rptd'] = pd.to_datetime(df['date_rptd'])\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'])\n",
    "\n",
    "# Display the updated DataFrame with the new formatted date_rptd and date_occ columns\n",
    "print(df[['date_rptd', 'date_occ']].head())\n",
    "print(df[['date_rptd', 'date_occ']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Date Occurred and Time Occ into a single Timestamp and remove the orinal Time Occ col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         datetime_occ\n",
      "0 2020-11-04 17:00:00\n",
      "1 2020-03-10 20:37:00\n",
      "2 2020-09-09 06:30:00\n",
      "3 2020-05-02 18:00:00\n",
      "4 2020-07-07 13:40:00\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Combine date_occ and time_occ into a single datetime column\n",
    "df['datetime_occ'] = pd.to_datetime(df['date_occ'].dt.strftime('%Y-%m-%d') + ' ' + df['time_occ'].astype(str).str.zfill(4).str[:2] + ':' + df['time_occ'].astype(str).str.zfill(4).str[2:] + ':00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Drop the original time_occ and date_occ columns\n",
    "df.drop(columns=['time_occ', 'date_occ'], inplace=True)\n",
    "\n",
    "# Reorder columns to place datetime_occ in the original position of time_occ\n",
    "cols = df.columns.tolist()\n",
    "time_occ_index = cols.index('datetime_occ')\n",
    "cols.insert(3, cols.pop(time_occ_index))\n",
    "df = df[cols]\n",
    "\n",
    "# Display the updated DataFrame with the modified datetime_occ column\n",
    "print(df[['datetime_occ']].head())\n",
    "# Display the data type of the datetime_occ column\n",
    "print(df['datetime_occ'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Category Type Cols to Category types for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtype\n",
    "categorical_columns = ['area_name', 'crm_cd_desc', 'mocodes', 'vict_sex', 'vict_descent', 'premis_desc', 'weapon_desc', 'status', 'status_desc', 'location', 'cross_street']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Various Codes to Short Ints for space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area              int16\n",
      "rpt_dist_no       int16\n",
      "part_1_2          int16\n",
      "crm_cd            int16\n",
      "vict_age          int16\n",
      "premis_cd         int16\n",
      "weapon_used_cd    int16\n",
      "crm_cd_1          int16\n",
      "crm_cd_2          int16\n",
      "crm_cd_3          int16\n",
      "crm_cd_4          int16\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Recheck the integer columns as some may have changed and convert to a short int\n",
    "integer_columns = ['area', 'rpt_dist_no', 'part_1_2', 'crm_cd', 'vict_age', 'premis_cd', 'weapon_used_cd', 'crm_cd_1', 'crm_cd_2', 'crm_cd_3', 'crm_cd_4']\n",
    "for col in integer_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('int16')\n",
    "\n",
    "# Display the columns and their data types\n",
    "print(df[integer_columns].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Lat and Lon Cols to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat    float64\n",
      "lon    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert latitude and longitude to float64\n",
    "df['lat'] = df['lat'].astype('float64')\n",
    "df['lon'] = df['lon'].astype('float64')\n",
    "\n",
    "# Verify changes\n",
    "print(df[['lat', 'lon']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the df into Dims and Facts\n",
    "See Schema here:\n",
    "https://lucid.app/lucidspark/a6f7a7bf-63d8-4aa7-ac61-6caa235ac916/edit?invitationId=inv_43e7079e-9d82-4f94-8907-0b93e812a852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_area         int16\n",
      "area_name    category\n",
      "dtype: object\n",
      "   fk_area   area_name\n",
      "0        3   Southwest\n",
      "1        9    Van Nuys\n",
      "2        4  Hollenbeck\n",
      "3        2     Rampart\n",
      "4       13      Newton\n"
     ]
    }
   ],
   "source": [
    "# Create dimension tables\n",
    "dim_area = (\n",
    "    df[['area', 'area_name']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'area': 'fk_area'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_area.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_area.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fk_crm_cd                               crm_cd_desc\n",
      "0        480                             BIKE - STOLEN\n",
      "1        343  SHOPLIFTING-GRAND THEFT ($950.01 & OVER)\n",
      "2        510                          VEHICLE - STOLEN\n",
      "3        648                                     ARSON\n",
      "4        310                                  BURGLARY\n"
     ]
    }
   ],
   "source": [
    "dim_crime = (\n",
    "    df[['crm_cd', 'crm_cd_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'crm_cd': 'fk_crm_cd'})\n",
    ")\n",
    "# Display a few rows of the dimension table\n",
    "print(dim_crime.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Victim Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_sex    category\n",
      "sex_desc      object\n",
      "dtype: object\n",
      "  vict_sex sex_desc\n",
      "0        X  UNKNOWN\n",
      "1        M     Male\n",
      "3        F   Female\n",
      "4        H  UNKNOWN\n"
     ]
    }
   ],
   "source": [
    "dim_victim_sex = (\n",
    "    df[['vict_sex']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Set any missing data to 'X'\n",
    "dim_victim_sex['vict_sex'] = dim_victim_sex['vict_sex'].fillna('X')\n",
    "\n",
    "# Add sex_desc column\n",
    "dim_victim_sex['sex_desc'] = dim_victim_sex['vict_sex'].map({\n",
    "    'M': 'Male',\n",
    "    'F': 'Female',\n",
    "    'X': 'UNKNOWN',\n",
    "    'H': 'UNKNOWN'\n",
    "})\n",
    "\n",
    "# Drop duplicates\n",
    "dim_victim_sex = dim_victim_sex.drop_duplicates()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "dim_victim_sex = dim_victim_sex.dropna()\n",
    "\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_victim_sex.dtypes)\n",
    "print(dim_victim_sex.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Victim Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_descent    category\n",
      "descent_desc      object\n",
      "dtype: object\n",
      "   vict_descent                    descent_desc\n",
      "0             X                         Unknown\n",
      "1             O                           Other\n",
      "3             W                           White\n",
      "4             H          Hispanic/Latin/Mexican\n",
      "5             B                           Black\n",
      "6             A                     Other Asian\n",
      "7             K                          Korean\n",
      "8             C                         Chinese\n",
      "9             F                        Filipino\n",
      "10            V                      Vietnamese\n",
      "11            I  American Indian/Alaskan Native\n",
      "12            P                Pacific Islander\n",
      "13            J                        Japanese\n",
      "14            G                       Guamanian\n",
      "15            D                       Cambodian\n",
      "16            Z                    Asian Indian\n",
      "17            U                        Hawaiian\n",
      "18            S                          Samoan\n",
      "19            L                         Laotian\n"
     ]
    }
   ],
   "source": [
    "dim_victim = (\n",
    "    df[['vict_descent']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Set any missing data to 'X'\n",
    "dim_victim['vict_descent'] = dim_victim['vict_descent'].fillna('X')\n",
    "\n",
    "# Add descent_desc column\n",
    "dim_victim['descent_desc'] = dim_victim['vict_descent'].map({\n",
    "    'A': 'Other Asian',\n",
    "    'B': 'Black',\n",
    "    'C': 'Chinese',\n",
    "    'D': 'Cambodian',\n",
    "    'F': 'Filipino',\n",
    "    'G': 'Guamanian',\n",
    "    'H': 'Hispanic/Latin/Mexican',\n",
    "    'I': 'American Indian/Alaskan Native',\n",
    "    'J': 'Japanese',\n",
    "    'K': 'Korean',\n",
    "    'L': 'Laotian',\n",
    "    'O': 'Other',\n",
    "    'P': 'Pacific Islander',\n",
    "    'S': 'Samoan',\n",
    "    'U': 'Hawaiian',\n",
    "    'V': 'Vietnamese',\n",
    "    'W': 'White',\n",
    "    'X': 'Unknown',\n",
    "    'Z': 'Asian Indian'\n",
    "})\n",
    "\n",
    "# Drop duplicates\n",
    "dim_victim = dim_victim.drop_duplicates()\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "dim_victim = dim_victim.dropna()\n",
    "\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_victim.dtypes)\n",
    "print(dim_victim.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Premises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_premis_cd       int16\n",
      "premis_desc     category\n",
      "dtype: object\n",
      "   fk_premis_cd                                   premis_desc\n",
      "0           502  MULTI-UNIT DWELLING (APARTMENT, DUPLEX, ETC)\n",
      "1           405                                CLOTHING STORE\n",
      "2           101                                        STREET\n",
      "3           221                                PUBLIC STORAGE\n",
      "4           201                                 JEWELRY STORE\n"
     ]
    }
   ],
   "source": [
    "dim_premise = (\n",
    "    df[['premis_cd', 'premis_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'premis_cd': 'fk_premis_cd'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_premise.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_premise.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_weapon_used_cd       int16\n",
      "weapon_desc          category\n",
      "dtype: object\n",
      "   fk_weapon_used_cd                                     weapon_desc\n",
      "0                  0                                             NaN\n",
      "1                400  STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)\n",
      "2                511                                   VERBAL THREAT\n",
      "3                201        KNIFE WITH BLADE OVER 6 INCHES IN LENGTH\n",
      "4                500                     UNKNOWN WEAPON/OTHER WEAPON\n"
     ]
    }
   ],
   "source": [
    "dim_weapon = (\n",
    "    df[['weapon_used_cd', 'weapon_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'weapon_used_cd': 'fk_weapon_used_cd'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_weapon.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_weapon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fk_status      category\n",
      "status_desc    category\n",
      "dtype: object\n",
      "  fk_status   status_desc\n",
      "0        IC   Invest Cont\n",
      "1        AA  Adult Arrest\n",
      "2        AO   Adult Other\n",
      "3        JA    Juv Arrest\n",
      "4        JO     Juv Other\n"
     ]
    }
   ],
   "source": [
    "dim_status = (\n",
    "    df[['status', 'status_desc']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={'status': 'fk_status'})\n",
    ")\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_status.dtypes)\n",
    "print(dim_status.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat                   float64\n",
      "lon                   float64\n",
      "geo_place_id           object\n",
      "geo_osm_type           object\n",
      "geo_osm_id             object\n",
      "geo_display_name       object\n",
      "geo_road               object\n",
      "geo_neighbourhood      object\n",
      "geo_suburb             object\n",
      "geo_city               object\n",
      "geo_state              object\n",
      "geo_ISO3166-2-lvl4     object\n",
      "geo_postcode           object\n",
      "geo_country            object\n",
      "geo_country_code       object\n",
      "geo_boundingbox        object\n",
      "dtype: object\n",
      "       lat       lon geo_place_id geo_osm_type geo_osm_id geo_display_name  \\\n",
      "0  34.0210 -118.3002         None         None       None             None   \n",
      "1  34.1576 -118.4387         None         None       None             None   \n",
      "2  34.0820 -118.2130         None         None       None             None   \n",
      "3  34.0642 -118.2771         None         None       None             None   \n",
      "4  34.0536 -118.2788         None         None       None             None   \n",
      "\n",
      "  geo_road geo_neighbourhood geo_suburb geo_city geo_state geo_ISO3166-2-lvl4  \\\n",
      "0     None              None       None     None      None               None   \n",
      "1     None              None       None     None      None               None   \n",
      "2     None              None       None     None      None               None   \n",
      "3     None              None       None     None      None               None   \n",
      "4     None              None       None     None      None               None   \n",
      "\n",
      "  geo_postcode geo_country geo_country_code geo_boundingbox  \n",
      "0         None        None             None            None  \n",
      "1         None        None             None            None  \n",
      "2         None        None             None            None  \n",
      "3         None        None             None            None  \n",
      "4         None        None             None            None  \n"
     ]
    }
   ],
   "source": [
    "dim_location = (\n",
    "    df[['lat', 'lon']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Add additional columns based on Schema at https://geocode.maps.co/reverse\n",
    "# This data will be added downstream in the ETL process\n",
    "dim_location['geo_place_id'] = None\n",
    "dim_location['geo_osm_type'] = None\n",
    "dim_location['geo_osm_id'] = None\n",
    "dim_location['geo_display_name'] = None\n",
    "dim_location['geo_road'] = None\n",
    "dim_location['geo_neighbourhood'] = None\n",
    "dim_location['geo_suburb'] = None\n",
    "dim_location['geo_city'] = None\n",
    "dim_location['geo_state'] = None\n",
    "dim_location['geo_ISO3166-2-lvl4'] = None\n",
    "dim_location['geo_postcode'] = None\n",
    "dim_location['geo_country'] = None\n",
    "dim_location['geo_country_code'] = None\n",
    "dim_location['geo_boundingbox'] = None\n",
    "# Show datatypes of the dimension table\n",
    "print(dim_location.dtypes)\n",
    "\n",
    "# Show some sample data from the dimension table\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972000 entries, 0 to 971999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   dr_no           972000 non-null  object        \n",
      " 1   date_rptd       972000 non-null  datetime64[ns]\n",
      " 2   datetime_occ    972000 non-null  datetime64[ns]\n",
      " 3   rpt_dist_no     972000 non-null  int16         \n",
      " 4   vict_age        972000 non-null  int16         \n",
      " 5   lat             972000 non-null  float64       \n",
      " 6   lon             972000 non-null  float64       \n",
      " 7   area            972000 non-null  int16         \n",
      " 8   premis_cd       972000 non-null  int16         \n",
      " 9   crm_cd          972000 non-null  int16         \n",
      " 10  vict_sex        972000 non-null  category      \n",
      " 11  vict_descent    972000 non-null  category      \n",
      " 12  weapon_used_cd  972000 non-null  int16         \n",
      " 13  status          972000 non-null  category      \n",
      "dtypes: category(3), datetime64[ns](2), float64(2), int16(6), object(1)\n",
      "memory usage: 51.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dr_no",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_rptd",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "datetime_occ",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "rpt_dist_no",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "vict_age",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "area",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "premis_cd",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "crm_cd",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "vict_sex",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "vict_descent",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "weapon_used_cd",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "status",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7cce598e-491a-40bf-8e22-d4372f23343c",
       "rows": [
        [
         "0",
         "20-03-20258",
         "2020-11-11 00:00:00",
         "2020-11-04 17:00:00",
         "356",
         "19",
         "34.021",
         "-118.3002",
         "3",
         "502",
         "480",
         "X",
         "X",
         "0",
         "IC"
        ],
        [
         "1",
         "20-09-07217",
         "2023-05-10 00:00:00",
         "2020-03-10 20:37:00",
         "964",
         "19",
         "34.1576",
         "-118.4387",
         "9",
         "405",
         "343",
         "M",
         "O",
         "0",
         "IC"
        ],
        [
         "2",
         "20-04-12582",
         "2020-09-09 00:00:00",
         "2020-09-09 06:30:00",
         "413",
         "0",
         "34.082",
         "-118.213",
         "4",
         "101",
         "510",
         "Unknown",
         "Unknown",
         "0",
         "IC"
        ],
        [
         "3",
         "20-02-09713",
         "2020-05-03 00:00:00",
         "2020-05-02 18:00:00",
         "245",
         "0",
         "34.0642",
         "-118.2771",
         "2",
         "101",
         "510",
         "Unknown",
         "Unknown",
         "0",
         "IC"
        ],
        [
         "4",
         "20-02-00759",
         "2020-07-07 00:00:00",
         "2020-07-07 13:40:00",
         "265",
         "0",
         "34.0536",
         "-118.2788",
         "2",
         "101",
         "648",
         "X",
         "X",
         "0",
         "IC"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr_no</th>\n",
       "      <th>date_rptd</th>\n",
       "      <th>datetime_occ</th>\n",
       "      <th>rpt_dist_no</th>\n",
       "      <th>vict_age</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>area</th>\n",
       "      <th>premis_cd</th>\n",
       "      <th>crm_cd</th>\n",
       "      <th>vict_sex</th>\n",
       "      <th>vict_descent</th>\n",
       "      <th>weapon_used_cd</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20-03-20258</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>2020-11-04 17:00:00</td>\n",
       "      <td>356</td>\n",
       "      <td>19</td>\n",
       "      <td>34.0210</td>\n",
       "      <td>-118.3002</td>\n",
       "      <td>3</td>\n",
       "      <td>502</td>\n",
       "      <td>480</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-09-07217</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>2020-03-10 20:37:00</td>\n",
       "      <td>964</td>\n",
       "      <td>19</td>\n",
       "      <td>34.1576</td>\n",
       "      <td>-118.4387</td>\n",
       "      <td>9</td>\n",
       "      <td>405</td>\n",
       "      <td>343</td>\n",
       "      <td>M</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-04-12582</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>2020-09-09 06:30:00</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0820</td>\n",
       "      <td>-118.2130</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>510</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20-02-09713</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020-05-02 18:00:00</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0642</td>\n",
       "      <td>-118.2771</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>510</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-02-00759</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2020-07-07 13:40:00</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0536</td>\n",
       "      <td>-118.2788</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>648</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>IC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dr_no  date_rptd        datetime_occ  rpt_dist_no  vict_age      lat  \\\n",
       "0  20-03-20258 2020-11-11 2020-11-04 17:00:00          356        19  34.0210   \n",
       "1  20-09-07217 2023-05-10 2020-03-10 20:37:00          964        19  34.1576   \n",
       "2  20-04-12582 2020-09-09 2020-09-09 06:30:00          413         0  34.0820   \n",
       "3  20-02-09713 2020-05-03 2020-05-02 18:00:00          245         0  34.0642   \n",
       "4  20-02-00759 2020-07-07 2020-07-07 13:40:00          265         0  34.0536   \n",
       "\n",
       "        lon  area  premis_cd  crm_cd vict_sex vict_descent  weapon_used_cd  \\\n",
       "0 -118.3002     3        502     480        X            X               0   \n",
       "1 -118.4387     9        405     343        M            O               0   \n",
       "2 -118.2130     4        101     510  Unknown      Unknown               0   \n",
       "3 -118.2771     2        101     510  Unknown      Unknown               0   \n",
       "4 -118.2788     2        101     648        X            X               0   \n",
       "\n",
       "  status  \n",
       "0     IC  \n",
       "1     IC  \n",
       "2     IC  \n",
       "3     IC  \n",
       "4     IC  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create fact table\n",
    "crime_facts = df[\n",
    "    [\n",
    "        # Unique Facts\n",
    "        'dr_no', 'date_rptd', 'datetime_occ', 'rpt_dist_no', 'vict_age', \n",
    "        # Dim Locations\n",
    "        'lat', 'lon', \n",
    "        # Dim Area\n",
    "        'area', \n",
    "        # Dim Premise\n",
    "        'premis_cd',\n",
    "        # Dim Crime\n",
    "        'crm_cd', \n",
    "        # Dim Victim Sex\n",
    "        'vict_sex', \n",
    "        # Dim Victim Descent\n",
    "        'vict_descent',\n",
    "        # Dim Weapon\n",
    "        'weapon_used_cd',\n",
    "        # Dim Status \n",
    "        'status'\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Handle missing data\n",
    "crime_facts['vict_sex'] = crime_facts['vict_sex'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "crime_facts['vict_descent'] = crime_facts['vict_descent'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "crime_facts['status'] = crime_facts['status'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "\n",
    "# Display schema and types\n",
    "print(crime_facts.info())\n",
    "\n",
    "# Display fact table\n",
    "display(crime_facts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Post Processes - Retrieve Geo Code into Location Dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Location Dim from the Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat       lon geo_place_id geo_osm_type geo_osm_id  \\\n",
      "0   33.8201 -118.3015    281393593          way   13356241   \n",
      "6   34.0326 -118.3941    284925955          way  165791832   \n",
      "7   33.9875 -118.4668    281444680          way  168954633   \n",
      "11  34.1707 -118.6565    285003597          way  402526611   \n",
      "12  33.9638 -118.2629    281472844          way  165899885   \n",
      "\n",
      "                                     geo_display_name               geo_road  \\\n",
      "0   Halldale Avenue, Los Angeles, California, 9050...        Halldale Avenue   \n",
      "6   South Canfield Avenue, Castle Heights, Los Ang...  South Canfield Avenue   \n",
      "7   Venice Way, Venice Canal Historic District, Ve...             Venice Way   \n",
      "11  Burbank Boulevard, Los Angeles, Los Angeles Co...      Burbank Boulevard   \n",
      "12  Stanford Avenue, Florence, Los Angeles, Los An...        Stanford Avenue   \n",
      "\n",
      "                 geo_neighbourhood geo_suburb     geo_city   geo_state  \\\n",
      "0                             None       None  Los Angeles  California   \n",
      "6                   Castle Heights       None  Los Angeles  California   \n",
      "7   Venice Canal Historic District     Venice  Los Angeles  California   \n",
      "11                            None       None  Los Angeles  California   \n",
      "12                            None   Florence  Los Angeles  California   \n",
      "\n",
      "   geo_ISO3166-2-lvl4 geo_postcode    geo_country geo_country_code  \\\n",
      "0               US-CA        90501  United States               us   \n",
      "6               US-CA        90034  United States               us   \n",
      "7               US-CA        90292  United States               us   \n",
      "11              US-CA        91307  United States               us   \n",
      "12              US-CA        90001  United States               us   \n",
      "\n",
      "                                      geo_boundingbox  \n",
      "0   ['33.819016', '33.8208781', '-118.3015108', '-...  \n",
      "6   ['34.0296448', '34.035801', '-118.3953219', '-...  \n",
      "7   ['33.9874163', '33.9875684', '-118.468556', '-...  \n",
      "11  ['34.1702241', '34.1712426', '-118.6575549', '...  \n",
      "12  ['33.9601434', '33.9747425', '-118.262981', '-...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Set the pickle file path\n",
    "pickle_file = 'dim_location.pkl'\n",
    "pickle_path = os.path.join(locations_data['Rel_Pickes_Dir'], pickle_file)\n",
    "\n",
    "# Check if the pickle file is zipped\n",
    "if os.path.exists(pickle_path + '.zip'):\n",
    "\twith zipfile.ZipFile(pickle_path + '.zip', 'r') as z:\n",
    "\t\twith z.open(pickle_file) as f:\n",
    "\t\t\tdim_location = pd.read_pickle(f)\n",
    "else:\n",
    "\t# Load the dimension table from the pickle file\n",
    "\ttry:\n",
    "\t\tdim_location = pd.read_pickle(pickle_path)\n",
    "\texcept FileNotFoundError:\n",
    "\t\tprint(\"Pickle file not found. Please ensure the file exists.\")\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Locations that need to be Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the df: 0\n"
     ]
    }
   ],
   "source": [
    "tmp_locs_to_be_processed = dim_location[dim_location['geo_place_id'].isnull()][['lat', 'lon']].drop_duplicates()\n",
    "print(f\"Number of records in the df: {len(tmp_locs_to_be_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'API_Key': '679e7xxxxx', 'Reverse_URL': 'https://geocode.maps.co/reverse', 'Max_Lookups': 50000, 'Rate_Limit_per_Sec': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Set the path for the JSON file\n",
    "credentials_dir = locations_data['Credentials_Dir']\n",
    "json_file_path = os.path.join(credentials_dir, 'geocode_api_key.json')\n",
    "\n",
    "# Read the credentials from the JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    api_key_data = json.load(f)\n",
    "\n",
    "geo_api_credentials = {\n",
    "    'API_Key': api_key_data['API_Key'],\n",
    "    'Reverse_URL': api_key_data['Reverse_URL'],\n",
    "    'Max_Lookups': api_key_data['Max_Lookups'],\n",
    "    'Rate_Limit_per_Sec': api_key_data['Rate_Limit_per_Sec']\n",
    "}\n",
    "\n",
    "# Mask the API key for security\n",
    "masked_key = geo_api_credentials['API_Key'][:5] + 'xxxxx'\n",
    "geo_api_credentials['API_Key'] = masked_key\n",
    "\n",
    "print(geo_api_credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the GeoCode API to Fetch Location Details using the Reverse Lookup from the Lat/Lon\n",
    "See https://geocode.maps.co/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Func for the Fetch\n",
    "This will be moved to Common Funcs Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def Fetch_Geo_Data(api_credentials, locations):\n",
    "    base_url = api_credentials['Reverse_URL']\n",
    "    api_key = api_credentials['API_Key']\n",
    "    max_lookups = api_credentials['Max_Lookups']\n",
    "    rate_limit_per_sec = api_credentials['Rate_Limit_per_Sec']\n",
    "    \n",
    "    geo_data = []\n",
    "    \n",
    "    for index, row in tqdm(locations.iterrows(), total=locations.shape[0], desc=\"Fetching Geo Data\"):\n",
    "        if len(geo_data) >= max_lookups:\n",
    "            print(\"Reached the maximum number of lookups for the day.\")\n",
    "            break\n",
    "        \n",
    "        params = {\n",
    "            'lat': row['lat'],\n",
    "            'lon': row['lon'],\n",
    "            'api_key': api_key\n",
    "        }\n",
    "        \n",
    "        attempts = 0\n",
    "        while attempts < 3:\n",
    "            try:\n",
    "                response = requests.get(base_url, params=params)\n",
    "                url = f\"{base_url}?lat={row['lat']}&lon={row['lon']}&api_key={api_key}\"\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    if 'place_id' not in response.json():\n",
    "                        print(f\"Response content for lat: {row['lat']}, lon: {row['lon']} - {response.json()}\")\n",
    "                    geo_data.append(response.json())\n",
    "                    break\n",
    "                else:\n",
    "                    attempts += 1\n",
    "                    time.sleep(rate_limit_per_sec)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                attempts += 1\n",
    "                time.sleep(rate_limit_per_sec)\n",
    "        \n",
    "        if attempts == 3:\n",
    "            print(f\"Failed to fetch data for lat: {row['lat']}, lon: {row['lon']} after 3 attempts.\")\n",
    "            geo_data.append(None)\n",
    "    \n",
    "    return geo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now call the Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Geo Data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "        lat       lon geo_place_id geo_osm_type geo_osm_id  \\\n",
      "0   33.8201 -118.3015    281393593          way   13356241   \n",
      "6   34.0326 -118.3941    284925955          way  165791832   \n",
      "7   33.9875 -118.4668    281444680          way  168954633   \n",
      "11  34.1707 -118.6565    285003597          way  402526611   \n",
      "12  33.9638 -118.2629    281472844          way  165899885   \n",
      "\n",
      "                                     geo_display_name               geo_road  \\\n",
      "0   Halldale Avenue, Los Angeles, California, 9050...        Halldale Avenue   \n",
      "6   South Canfield Avenue, Castle Heights, Los Ang...  South Canfield Avenue   \n",
      "7   Venice Way, Venice Canal Historic District, Ve...             Venice Way   \n",
      "11  Burbank Boulevard, Los Angeles, Los Angeles Co...      Burbank Boulevard   \n",
      "12  Stanford Avenue, Florence, Los Angeles, Los An...        Stanford Avenue   \n",
      "\n",
      "                 geo_neighbourhood geo_suburb     geo_city   geo_state  \\\n",
      "0                             None       None  Los Angeles  California   \n",
      "6                   Castle Heights       None  Los Angeles  California   \n",
      "7   Venice Canal Historic District     Venice  Los Angeles  California   \n",
      "11                            None       None  Los Angeles  California   \n",
      "12                            None   Florence  Los Angeles  California   \n",
      "\n",
      "   geo_ISO3166-2-lvl4 geo_postcode    geo_country geo_country_code  \\\n",
      "0               US-CA        90501  United States               us   \n",
      "6               US-CA        90034  United States               us   \n",
      "7               US-CA        90292  United States               us   \n",
      "11              US-CA        91307  United States               us   \n",
      "12              US-CA        90001  United States               us   \n",
      "\n",
      "                                      geo_boundingbox  \n",
      "0   ['33.819016', '33.8208781', '-118.3015108', '-...  \n",
      "6   ['34.0296448', '34.035801', '-118.3953219', '-...  \n",
      "7   ['33.9874163', '33.9875684', '-118.468556', '-...  \n",
      "11  ['34.1702241', '34.1712426', '-118.6575549', '...  \n",
      "12  ['33.9601434', '33.9747425', '-118.262981', '-...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "geo_data = Fetch_Geo_Data(geo_api_credentials, tmp_locs_to_be_processed)\n",
    "print(geo_data[:5])\n",
    "# Update the dim_location DataFrame with the fetched geo data\n",
    "for i, data in enumerate(geo_data):\n",
    "    if data:\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_place_id'] = data.get('place_id')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_osm_type'] = data.get('osm_type')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_osm_id'] = data.get('osm_id')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_display_name'] = data.get('display_name')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_road'] = data.get('address', {}).get('road')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_neighbourhood'] = data.get('address', {}).get('neighbourhood')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_suburb'] = data.get('address', {}).get('suburb')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_city'] = data.get('address', {}).get('city')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_state'] = data.get('address', {}).get('state')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_ISO3166-2-lvl4'] = data.get('address', {}).get('ISO3166-2-lvl4')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_postcode'] = data.get('address', {}).get('postcode')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_country'] = data.get('address', {}).get('country')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_country_code'] = data.get('address', {}).get('country_code')\n",
    "        dim_location.at[tmp_locs_to_be_processed.index[i], 'geo_boundingbox'] = data.get('boundingbox')\n",
    "\n",
    "# Display updated dim_location DataFrame\n",
    "print(dim_location.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle & Zip Dims, Facts for Downstream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "pickles_dir = locations_data['Rel_Pickes_Dir']\n",
    "os.makedirs(pickles_dir, exist_ok=True)\n",
    "\n",
    "# Define a list of the dimension and fact tables along with their filenames\n",
    "pickle_files = [\n",
    "    (dim_area, 'dim_area.pkl'),\n",
    "    (dim_crime, 'dim_crime.pkl'),\n",
    "    (dim_victim, 'dim_victim.pkl'),\n",
    "    (dim_premise, 'dim_premise.pkl'),\n",
    "    (dim_weapon, 'dim_weapon.pkl'),\n",
    "    (dim_status, 'dim_status.pkl'),\n",
    "    (dim_location, 'dim_location.pkl'),\n",
    "    (crime_facts, 'crime_facts.pkl')\n",
    "]\n",
    "\n",
    "# Use a while loop to pickle the tables\n",
    "i = 0\n",
    "while i < len(pickle_files):\n",
    "    df, filename = pickle_files[i]\n",
    "    pickle_path = os.path.join(pickles_dir, filename)\n",
    "    df.to_pickle(pickle_path)\n",
    "    \n",
    "    # Zip the pickle file\n",
    "    with zipfile.ZipFile(pickle_path + '.zip', 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "        z.write(pickle_path, filename)\n",
    "    \n",
    "    # Remove the uncompressed pickle file\n",
    "    os.remove(pickle_path)\n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
